{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb14264",
   "metadata": {},
   "source": [
    "# Chapter 15 - Backpropagation\n",
    "\n",
    "The backpropagation algorithm is the classical feedforward artificial neural network. It is the technique still used to train large deep learning networks. In this tutorial, you will discover how to implement the backpropagation algorithm from scratch with Perl. After completing this tutorial, you will know:\n",
    "\n",
    "- How to forward-propagate an input to calculate an output.\n",
    "- How to backpropagate error and train a network.\n",
    "- How to apply the backpropagation algorithm to a real-world predictive modeling problem.\n",
    "\n",
    "Let’s get started.\n",
    "\n",
    "## 15.1 Description\n",
    "\n",
    "This section provides a brief introduction to the Backpropagation Algorithm and the Wheat Seeds dataset that we will be using in this tutorial.\n",
    "\n",
    "### 15.1.1 Backpropagation Algorithm\n",
    "\n",
    "The Backpropagation algorithm is a supervised learning method for multilayer feedforward networks from the field of Artificial Neural Networks. Feedforward neural networks are inspired by the information processing of one or more neural cells, called a neuron. A neuron accepts input signals via its dendrites, which pass the electrical signal down to the cell body. The axon carries the signal out to synapses, which are the connections of a cell’s axon to other cell’s dendrites.\n",
    "\n",
    "The principle of the backpropagation approach is to model a given function by modifying internal weightings of input signals to produce an expected output signal. The system is trained using a supervised learning method where the error between the system’s output and a known expected output is presented to the system and used to modify its internal state.\n",
    "\n",
    "Technically, the backpropagation algorithm is a method for training the weights in a multilayer feedforward neural network. As such, it requires a network structure to be defined of one or more layers where one layer is fully connected to the next layer. A standard network structure is one input layer, one hidden layer, and one output layer. Backpropagation can be used for both classification and regression problems, but we will focus on classification in this tutorial.\n",
    "\n",
    "In classification problems, best results are achieved when the network has one neuron in the output layer for each class value. For example, a 2-class or binary classification problem with the class values of A and B. These expected outputs would have to be transformed into binary vectors with one column for each class value. Such as [1, 0] and [0, 1] for A and B respectively. This is called a one hot encoding.\n",
    "\n",
    "### 15.1.2 Wheat Seeds Dataset\n",
    "\n",
    "In this tutorial we will use the Wheat Seeds Dataset. This dataset involves the prediction of the species of wheat seeds. The baseline performance on the problem is approximately 28%. You can learn more about it in Appendix A, Section A.10. Download the dataset and save it into your current working directory with the filename seeds dataset.csv. The dataset is in tab-separated format, so you must convert it to CSV using a text editor or a spreadsheet program.\n",
    "\n",
    "## 15.2 Tutorial\n",
    "\n",
    "This tutorial is broken down into 6 parts:\n",
    "\n",
    "1. Initialize Network.\n",
    "2. Forward-Propagate.\n",
    "3. Backpropagate Error.\n",
    "4. Train Network.\n",
    "5. Predict.\n",
    "6. Wheat Seeds Case Study.\n",
    "\n",
    "These steps will provide the foundation that you need to implement the backpropagation algorithm from scratch and apply it to your own predictive modeling problems.\n",
    "\n",
    "### 15.2.1 Initialize Network\n",
    "\n",
    "Let’s start with something easy: the creation of a new network ready for training. Each neuron has a set of weights that need to be maintained. One weight for each input connection and an additional weight for the bias. We will need to store additional properties for a neuron during training, therefore we will use a dictionary to represent each neuron and store properties by names such as weights for the weights.\n",
    "\n",
    "A network is organized into layers. The input layer is really just a row from our training dataset. The first real layer is the hidden layer. This is followed by the output layer that has one neuron for each class value. We will organize layers as arrays of dictionaries and treat the whole network as an array of layers. It is good practice to initialize the network weights to small random numbers. In this case, will we use random numbers in the range of 0 to 1. Below is a function named initialize_network() that creates a new neural network ready for training. It accepts three parameters: the number of inputs n_inputs, the number of neurons to have in the hidden layer n_hidden and the number of outputs n_outputs. You can see that for the hidden layer we create n_hidden neurons and each neuron in the hidden layer has n_inputs + 1 weights, one for each input column in a dataset and an additional one for the bias.\n",
    "\n",
    "You can also see that the output layer that connects to the hidden layer has n_output neurons, each with n_hidden + 1 weights. This means that each neuron in the output layer connects to (has a weight for) each neuron in the hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75790dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from sml import SML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sml = SML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbb9d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = []\n",
    "\n",
    "    hidden_layer = []\n",
    "    for _ in range(n_hidden):\n",
    "        weights = mx.nd.random.uniform(shape=(n_inputs + 1,))\n",
    "        neuron = {'weights': weights}\n",
    "        hidden_layer.append(neuron)\n",
    "    network.append(hidden_layer)\n",
    "\n",
    "    output_layer = []\n",
    "    for _ in range(n_outputs):\n",
    "        weights = mx.nd.random.uniform(shape=(n_hidden + 1,))\n",
    "        neuron = {'weights': weights}\n",
    "        output_layer.append(neuron)\n",
    "    network.append(output_layer)\n",
    "\n",
    "    \"\"\" # Capa oculta: n_hidden neuronas, cada una con n_inputs + 1 pesos\n",
    "    hidden_weights = mx.nd.random.uniform(shape=(n_hidden, n_inputs + 1))\n",
    "\n",
    "    # Capa de salida: n_outputs neuronas, cada una con n_hidden + 1 pesos\n",
    "    output_weights = mx.nd.random.uniform(shape=(n_outputs, n_hidden + 1)) \"\"\"\n",
    "\n",
    "    #return [hidden_weights, output_weights]\n",
    "    return network\n",
    "\n",
    "sml.add_to_class(sml, 'initialize_network', initialize_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7cea8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hidden layer:\n",
      "Neuron[0] weights & bias: [0.7181762456893921, 0.03998935595154762, 0.7288185358047485]\n",
      "\n",
      "Output layer:\n",
      "Neuron[0] weights & bias: [0.24172033369541168, 0.8149715662002563]\n",
      "Neuron[1] weights & bias: [0.7259947657585144, 0.9137216806411743]\n"
     ]
    }
   ],
   "source": [
    "mx.random.seed(10)\n",
    "\n",
    "network = initialize_network(n_inputs=2, n_hidden=1, n_outputs=2)\n",
    "\n",
    "layer_names = ['Hidden', 'Output']\n",
    "\n",
    "\"\"\" for name, weights_matrix in zip(layer_names, network):\n",
    "    print(f\"\\n{name} layer:\")\n",
    "    for i, weights in enumerate(weights_matrix):\n",
    "        print(f\"Neuron[{i}] weights & bias: {weights.asnumpy().tolist()}\") \"\"\"\n",
    "\n",
    "for name, layer in zip(layer_names, network):\n",
    "    print(f\"\\n{name} layer:\")\n",
    "    for i, neuron in enumerate(layer):\n",
    "        weights = neuron['weights']\n",
    "        print(f\"Neuron[{i}] weights & bias: {weights.asnumpy().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43d54a",
   "metadata": {},
   "source": [
    "Running the example, you can see that the code prints out each layer one by one. You can see the hidden layer has one neuron with 2 input weights plus the bias. The output layer has 2 neurons, each with 1 weight plus the bias.\n",
    "\n",
    "Sample Output from Initializing a Network.\n",
    "\n",
    "Hidden layer:\n",
    "Neuron[0] weights & bias:[0.0416303447718782, 0.454492444728629, 0.834817218166915]\n",
    "\n",
    "Output layer:\n",
    "Neuron[0] weights & bias:[0.3359860301452, 0.565489403566136]\n",
    "Neuron[1] weights & bias:[0.00176691239174431, 0.18758951699996]\n",
    "\n",
    "Now that we know how to create and initialized a network, let's see how we can use it to calculate an output.\n",
    "\n",
    "## 15.2.2 Forward-Propagate\n",
    "\n",
    "We can calculate an output from a neural network by propagating an input signal through each layer until the output layer outputs its values. We call this forward-propagation. It is the technique we will need to generate predictions during training that will need to be corrected, and it is the method we will need after the network is trained to make predictions on new data. We can break forward-propagation down into three parts:\n",
    "\n",
    "1. Neuron Activation.\n",
    "2. Activation Function (Neuron Transfer).\n",
    "3. Forward-Propagation.\n",
    "\n",
    "### Neuron Activation\n",
    "\n",
    "The first step is to calculate the activation of one neuron given an input. The input could be a row from our training dataset, as in the case of the hidden layer. It may also be the outputs from each neuron in the hidden layer, in the case of the output layer. Neuron activation is calculated as the weighted sum of the inputs. Much like linear regression.\n",
    "\n",
    "$$\n",
    "\\text{activation} = \\text{bias} + \\sum_{i=1}^{n} \\text{weight}_i \\times \\text{input}_i\n",
    "$$\n",
    "\n",
    "Where `weight` is a network weight, `input` is an input value, `i` is the index of a weight or an input and `bias` is a special weight that has no input to multiply with (or you can think of the input as always being 1.0). Below is an implementation of this in a function named `activate()`. You can see that the function assumes that the bias is the last weight in the list of weights. This helps here and later to make the code easier to read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3435627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(weights, inputs):\n",
    "    bias = weights[-1]\n",
    "    weighted_sum = mx.nd.dot(weights[:-1], inputs)\n",
    "    return weighted_sum + bias\n",
    "\n",
    "sml.add_to_class(sml, 'activate', activate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe21578",
   "metadata": {},
   "source": [
    "Now, let’s see how to use the neuron activation.\n",
    "\n",
    "### Activation Function (Neuron Transfer)\n",
    "\n",
    "Once a neuron is activated, we need to transfer the activation to see what the neuron output actually is. Different transfer functions can be used. It is traditional to use the sigmoid activation function, but you can also use the tanh (hyperbolic tangent) function to transfer outputs. More recently, the rectifier transfer function has been popular with large deep learning networks.\n",
    "\n",
    "The sigmoid activation function looks like an S shape: it’s also called the logistic function. It can take any input value and produce a number between 0 and 1 on an S-curve. It is also a function of which we can easily calculate the derivative (slope) that we will need later when backpropagating error. We can transfer an activation function using the sigmoid function as follows:\n",
    "\n",
    "$$\n",
    "\\text{output} = \\frac{1}{1 + e^{-\\text{activation}}}\n",
    "$$\n",
    "\n",
    "Where _e_ is the base of the natural logarithms (Euler’s number). Below is a function named `transfer()` that implements the sigmoid equation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9db8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + mx.nd.exp(-activation))\n",
    "\n",
    "sml.add_to_class(sml, 'transfer', transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10130561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAGGCAYAAADGq0gwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABU8klEQVR4nO3dB3wU1drH8Se9AKEFQu/Sm9IEREA6qKBXRFBBVFQQL4oFUGk2VBS9Kld8FdR7kQtWUEF6F6SDiAQF6T20QEL6vp/nwMZ0Ekhmtvy+fsadnZ3ZnD077Oafc+YcH4fD4RAAAAAAgEfwtbsAAAAAAID8Q8gDAAAAAA9CyAMAAAAAD0LIAwAAAAAPQsgDAAAAAA9CyAMAAAAAD0LIAwAAAAAPQsgDAAAAAA9CyAMAAAAAD0LIAwAvtHz5cvHx8TG3ruS///2v1K5dWwICAqRYsWL58pz6OseNGyeuTMun5czP13P8+HG56667pGTJkuaYd999V1zRAw88IFWqVLG7GADgUQh5AOBBPvvsM/MLvXMJDg6WmjVrytChQ80v/flh3rx5BRKaIiMjzS/81atXl48//lj+7//+L8f9V69eLd26dZPy5cub11mpUiW57bbbZMaMGfleNnf01FNPyYIFC2TUqFEmPHft2tW2shw5csScM1u3brWtDADgTfztLgAAIP+99NJLUrVqVYmLizNh6MMPPzTh7LfffpPQ0NBrem59nsmTJ+d70NNWxZSUFPnXv/4lNWrUyHHfr776Svr06SONGzeWYcOGSfHixWXv3r2ycuVKExD79euXuu/FixfF39+1v+5efPFFGTlyZL4+59KlS6Vnz57yzDPPiN005I0fP9602Ol7lpa+X/q+AwDyj2t/6wEAroq2cDVt2tSsP/zww6bL3qRJk2TOnDnSt29fcUUnTpwwt7nppqkBs27duvLLL79IYGBgls/jpK18rk5DaH4HUa2H/OryWpC0ay4AIH/RXRMAvMAtt9xibrW160otZE2aNJGQkBAJDw+X++67Tw4fPpz6uHan1FY8lbZb6JX8+9//lnr16klQUJCUK1dOHn/8cTl79mzq49rCM3bsWLNeqlSpK153tmfPHmnWrFmmgKdKly6d7n5Wz6WthhqCNQBq99CPPvooy+vi9L52ddV60VCp9dKyZUvZvn27eVyP01ZHfZ527drJvn378lynKqufHR8fb7pcan0UKVJEbr/9djl06JDktsuuw+Ew71Xa9yi7a/+cx6Qtv74nt956q2kJbt68uXmN1apVk//85z+Zjtf3Usuqx+h7XKFCBenfv79ERUWZutb3Sg0cODC1PPozs7smLyYmRp5++mmpWLGieb5atWrJW2+9ZV5TVu/P7NmzpX79+mZfPc/mz59/xXoCAE9GSx4AeAENRUpb9LKjv3TrL+H6C/mECRPMNXzadfLnn3+WLVu2mFahRx991HS9W7RokbnOKzc0WGhXvY4dO8rgwYNl165dpvvohg0bzHNrS44OCqLh4bvvvjOPFS5cWBo2bJjtc1auXFmWLFliQo8GirzQ16LXp5UtW9aUKzk52XRv1TCVlVWrVsn3339vgqnSutHw89xzz5nwOmTIEDlz5oy8+eab8uCDD5puknmp0+xoC+z06dNN19NWrVqZ5+3Ro8cVX9/NN99s3pv7779fOnXqZMLW1dq9e7cZvOWhhx6SAQMGyLRp00wo09CqYUpduHBB2rRpIzt37jSv/4YbbjDhTutM3586deqY+h0zZow88sgjZl+lrykrGuQ00C5btsz8XO3eqdcWPvvssyYcv/POO+n21xD67bffmvdBw/B7770n//jHP+TAgQM5nu8A4NEcAACP8emnn2pTh2Px4sWOkydPOg4ePOiYOXOmo2TJko6QkBDHoUOHzH7Lli0z++mtSkhIcJQuXdpRv359x8WLF1Of78cffzT7jRkzJnXb448/brblxokTJxyBgYGOzp07O5KTk1O3f/DBB+Y5pk2blrpt7NixZpuW+0qmTp1q9tXnbt++vWP06NGOVatWpfsZTrqfPrfTbbfd5ggNDXUcPnw4dduff/7p8Pf3z/S69H5QUJBj7969qds++ugjs71MmTKO6Ojo1O2jRo0y25375qVOna/daevWreb+kCFD0pWnX79+mV5PdnQ/fa/SyvhzMp43aV9n5cqVzbaVK1emez+1Pp5++unUbfo6dL9vv/020/OmpKSY2w0bNph99OdkNGDAAPOznGbPnm32feWVV9Ltd9dddzl8fHwcu3fvTvca9RxIu23btm1m+/vvv3+FGgIAz0V3TQDwQNpqpi1T2t3tnnvuMS1j2kqmI1FmZePGjeYaLm0NSXsNm7Yc6ZQGc+fOvapyLF68WBISEuTJJ58UX9+/v3IGDRokYWFhV/282mKkXfK0i6S25Lz88sumhei6666TNWvWZHucttppmXr16mW6jTppl0u9jjErHTp0SNedsEWLFuZWW4u05Sjj9r/++uua61QHt1H//Oc/023XerSSdlF1trwpPae066TzNapvvvlGGjVqJHfccUem43M7LUTG1+7n55fptWv3Tc11P/30U6ZzXbvcOmkLsJ5bacsIAN6G7poA4IH0WiydOkEH84iIiDC/mKcNWRnt37/f3Op+GWkg0SB1NbJ7Xr2WTq/vcj5+Nbp06WKW2NhY2bRpk8yaNUumTJliulLqdAwZr81TGrp0tM2sRu/MbkRPnZohraJFi5pbDdBZbdeum9dap3qsvl9pw0t2z1WQMr52pSOZOl+jsyuwBt78oq9dA3jaAK2026fz8byWEQC8DSEPADyQDpThHF3T0+mUENrapIsObKLX2Wlrj15Dlh+0VSkv2zMODuJKsmtZ0xZOd32N7lBGALAa3TUBAGYgE6WDomSk25yP57ULXnbPq104daTPtM+bH5zB9ujRo1k+rq172nVSBxTJKKttVtVpVsfq3HHOAXPSHncttIVLpR3ZVF1Li6q2Nur8iznJ6zmjg/ucP38+3XZtnXU+DgDIGSEPAGDCkQYg7e6oQ/c7aYuYjpqYdlTHQoUKZRkUsqLXS2nXTB3xMG3LytSpU+XcuXO5Gi0yKzqyZk7XsmXXrVFbfbRMOuS+Bom0AS/jtV5W1mlGzusDtd7S0lFIr4Wz+6dOGp92uoLPP//8qp9Tu2pu27bNXPOZkfM9z8s50717d9Oy+MEHH6TbrqNqaljM7tpJAMDf6K4JADDTGLzxxhtmuP+2bduaCdOdw/3roCM6B5qTDp+vdGAMvSZOg5MO7pIVHahj1KhRpgulTlugQ+Nra5ROPaDTCuiccVejZ8+eUrVqVbnttttMcNGgogOq/PDDD+Z5dXtOUzosXLhQWrdubaZ0cAYKnWdt69atYkedZqTTBuj+Wk8ahnW6AQ2219ra2LlzZ3MNm05NoFMS6Hun0yLo+6RTDlwNfZ6vv/5aevfubQbE0fPj9OnTZgoFDbg6KIu+RzpdhN7Xa+009OlANfoeZqTvXfv27eWFF14w8/bp8fp+zZkzxww8k/E6RQBAZoQ8AICh85/p9W2vv/66jBgxwvwiriMmalBJO5/bnXfeKU888YTMnDnTzOOmrTXZhTxnqNIQoUFKg02JEiXMfGmvvfaaCUJX45NPPjG/9H/55ZemRU7LoAO5aDDQsuuAM9nREKKtac8884yMHj3aDKCi87hp65qzS6DVdZoVZ/j64osvTMujTmivI3JmHPAlL7S+tcVNR/zU116mTBkTnLQbp4bRq6Ejt+pcgjqZvT63tgpqC6aOSuqcw1B/rm7XwP/YY49JUlKSfPrpp1mGPB1wRgOizqung+nofhqKJ06caEbYBABcmY/Oo5CL/QAA8Gg6rcKOHTvkzz//tLsoAABcE67JAwB4HZ1GIS0Ndno9n867BwCAu6MlDwDgdcqWLWu6Ujrn6vvwww/N4ChbtmwxE6oDAODOuCYPAOB1dBCY//3vf3Ls2DEJCgqSli1bmmsECXgAAE9ASx4AAAAAeBCuyQMAAAAAD0LIAwAAAAAP4nXX5KWkpJg5lXQyVh8fH7uLAwAAAAC5olfanT9/XsqVK2fmFc2O14U8DXjXMpEsAAAAANjp4MGDUqFChWwf97qQpy14zooJCwsTV5CYmCgLFy6Uzp07S0BAgN3F8RrUu/Woc+tR59ajzq1HnVuPOrcedW69RBes8+joaNNg5cw02fG6kOfsoqkBz5VCXmhoqCmPq5xA3oB6tx51bj3q3HrUufWoc+tR59ajzq2X6MJ1fqXLzhh4BQAAAAA8CCEPAAAAADwIIQ8AAAAAPIjXXZOXW8nJyaYfrhX05/j7+0tcXJz5uchZYGBgjkPGAgAAAN6MkJfF3BPHjh2Ts2fPWvozy5QpY0b8ZO6+K9OAV7VqVRP2AAAAAKRHyMvAGfBKly5tRtOxInTpBO0XLlyQwoUL00KVy8nsjx49KpUqVSIUAwAAABkQ8tLQrpLOgFeyZElLg0tCQoIEBwcT8nKhVKlSJuglJSW53HC2AAAAgN1sTRQrV66U2267TcqVK2daZGbPnn3FY5YvXy433HCDBAUFSY0aNeSzzz7Lt/I4r8HTFjy4Lmc3Ta5fBAAAAFws5MXExEijRo1k8uTJudp/79690qNHD2nfvr1s3bpVnnzySXn44YdlwYIF+VouugC6Nt4fAAAAwEW7a3br1s0suTVlyhQz4Mbbb79t7tepU0dWr14t77zzjnTp0qUASwoAAAAA7sGtrslbu3atdOzYMd02DXfaoped+Ph4szhFR0ends3MOEWC3teRLvUaOV2soj/TeVuQP9fPz0+++eYb6dWrl9hJu9x26NBBTp06JcWKFctyH+2GO3z4cDl9+nSmx7SOtK70/dLXdLWc779VU2WAOrcDdW496tx61Lnn17l+7zuSHZKcmCwpiSmSkpTy93ri5fWklMyPXd7mvK+3jqTLz5OcIo4Ux6Ul+dKtbpMUSV1P+1jabbqPWXdk/XjabVkeb17U5d8B09xm2pbm90Q9NioqSmZ8MONSr6Ysjk99HsnFc2fxs3J8LPXNyPr9yWmf/HiOLI+Rgv25Dn1/SzgksZPrfLbk9t+cv7uNfBkREZFum97X4Hbx4kUJCQnJdMyECRNk/PjxmbYvXLgw07V3OledTmWgI13qQChWO3/+/DUdr//wX3vtNfPaTp48aQJU/fr15dlnn5Ubb7xRIiMjzTZn0LWLlknLoh9Q2ZVF5wzUf1hZPa7vjb7fek2nDr5yrRYtWnTNz4G8oc6tR51bjzq3HnVuHRNY4lNk3pfzJCUuxSzJccmp66lLfIokX0wWR4LDhCxHokNSEi7dmnXddqXHklJEuAw/1Xm5tt8XkTfBEuxSny2xsbGeF/KuxqhRo0yLkJOGhooVK0rnzp0lLCwsU7DQuep0KgMd6dIqGmY04BUpUuSarje7/fbbTQD6/PPPpVq1anL8+HFZunSpeV36WjO+XjuFh4fn+LjWv9ZFVmXW16OB/uabb76m90n/EqL/aDt16sQonRahzq1HnVuPOrcedZ53SfFJEnsyVuJOx0ncuTiJOxsncWcurcefjb+07Uz69YQLCWZJjEmUxFjXaNnwDfAVvwA/8fX3Nevp7l/eltPjPr4+lxa/y7e+PuLr55tpm3M9q8d0ZPS87K+LXP51z/ze55O72+SkZNnx+w6pV7+eaZjIuE+m48wPyNvPyO4YZ3nTyvQ7a37tk8V++bVPXsukjQkbtmxwqc+W3DbWuFXI01Y2DS5p6X0NAlm14ikdhVOXjPSNyvhm6WiN+qbqP1YrpzJwdtF0/uyroVM/rFq1ynSFbNu2rdmm1y9qC56TPv93332X2l1zzZo1MmTIENOqpq1rL774otxxxx2yZcsWady4sXkuHeRm/vz5MnLkSLNfy5YtZebMmbJp0yYTng8fPiy33nqrfPLJJ6kto9o9VlsPdT89EZs2bWqum2zWrJl53Pm8Z86cSe2uqd0zx4wZY1ojtQvuTTfdZLZnVR/mw9THJ8v38Grk1/Mg96hz61Hn1qPOrefNda5/MI4/Fy/Rh6Ml5niMxJy4vJy8dBt7IvbvbSdiJD7670tZromPSGChQAksHCgBhQLMbcb7ehsQGiD+wf7iH+R/6fby4hfk9/f9rB4LunSrgcyEszQhzQQnLxqMTf+YcXTeUbm++/Vee57bUee/nfnNpT5bclsOtwp5GjDmzZuXbpv+5U63FxRz7VcB/7VKQ57+VSzBLyFdqNEPxNx+eGnroy46DYUGu6yCbVoavnT6iu7du8uMGTNk//792V7bOG7cOPnggw9MiLv77rvNos+vx2nXVg2G77//vowYMcLs/9xzz5lr/7RFsXLlyvLmm2+a4LZ7924pUaJEpudft26dPPTQQ6ZrrQZQDZVjx47N1esGAMAbJF5MlLP7zsqZv87Iuf3nJPpQtJw/fN7cOpe8/r6iQSmkRIgEFwuW4OLBl26dS8b7xYIlKCzoUogrHCg+gT6y7Odl0qNXj9SpjQC4DltDngYE/cU/7RQJOjWCBoFKlSqZrpbaUvSf//zHPP7YY4+ZsKEh4sEHHzRdEb/88kuZO3dugZVRPzAnFJ4gdhh1YZT5a1huaLO9toYNGjTIjEKqcwlqi94999wjDRs2zLS/BjQNkB9//LHp8li3bl1T13p8Rq+88oq0bt3arGsY0/dlz549pkuouuuuu2TZsmUm5Om0GB9++KEpi3PkVP0ZGsanTp1qWvgy+te//iVdu3Y176uqWbOmaWXUsAcAgLeIPx8vUZFRZjmz54wJdLqc3XtWzh/J3XVYGs6KlC0ioaVCpVDpQumWjNs0uF1tS5i2cPgGXepZA8D12BryNm7caLrtOTmvnRswYIAJCUePHpUDBw6kPq7dDzXQPfXUUyYYVKhQwXQTZPqES/7xj3+YeQS12+Yvv/wiP/30k2lF0zp64IEH0u27a9cuE/7SXtPWvHnzLJ83bUjUgW60Rc8Z8Jzb1q9fb9Y1/OkHvzMUOpuV9bl37tyZ5fPrdm0NTEtbZwl5AABPdPH0RTn+63E5ufOkRO2MurRERpnWuJwEFgmU4tWKS7EqxSSsYpiElQ+TsAp/L0XKFTG9gADA1pDXrl27zMOWpqFBL6tj9Joxq+iHpbaoFXR3zfPR56VIWJFM3TXzSkObXhyqy+jRo81k8dr1MWPIu9q+v85r4dLSbVZOOQEAgDswA6sdOS/HthyTo5uPXrrdctR0t8xOoYhCEl47XErWLCnFqhYzoc65aNdKWs4AeNw1eXbQD9Pcdpm8WhqQApIDzM/J7wFftBumXqeXUa1atWT69OlmkBTn9XsbNmy45p9XvXp10zf/559/NtfjKW3Z0+fO7po/ndRer8tLS1siAQBwJ3qJx+ENh+XA6gNy8OeDcmTjETOCZVY0wJWqW0rC64RLqTqXbjXchRTPeiA5AMgLQp6H0InFe/fuba5V1O6VOh2DdofV7po9e/bMtH+/fv3khRdekEceecSMnKndYt966y3z2LX8lbBQoUIyePBgc+2d89pKLYPO6aHX82Xln//8p+neqT9fy7pgwQK6agIAXJ6OUnng5wOpoe7opqOX5nRLQ4fL1zBX5voyZil7Q1kp07iMBBe1bqomAN6HkOchdGTNFi1amKkKnNfF6XyAOpDK888/n2l/nXbihx9+MIFMp0to0KCBmcJAw9+1zhH4+uuvm9bJ+++/38z/p1MoaHArXrx4lvvraKA6OIt2K9UydOzY0Uzn8PLLL19TOQAAyO+55TTM7Z6/2ywntp/ItI9eF1fppkpSsXVFKd+ivEQ0jJCAEK6TA2AtQp6H0C6XOgWBLtnJeP1jq1atZNu2ban3v/jiC3O9nba+ZXfNpF7bl/H6Pp1iQRcnDYnvvfeeWbKS1fNqC6QuaT399NM5vGIAAAre6T2nTaDbM3+P7F2210x5lFbp+qVNoHMGOx0UhevmANiNkOfFdGoKHSWzfPnyJuzpFAg6B152E8sDAODp9I+QJ3eclB1f7jDLqV2nMg2MUqNLDanetbpU71RdQsNDbSsrAGSHkOfFjh07ZrpH6m3ZsmXNNX2vvvqq3cUCAMByJ3//O9jplAZpJwzXFroaXWuYRbtf6nV2AODKCHleTCcfd05ADgCAtzmz94z8+t9fTbDT1jsnv0A/E+jq9aknNW+tKUFhl0ahBgB3QcgDAABeI/FiokR+Fylbpm6RvUv3pm73DfA13TDr3l1Xat1ei9EvAbg1Qh4AAPB4p3eflg0fbpCtn26VuDNxlzb6iFTrUE0a3NdAavesLcHFCHYAPAMhLws6/D9cV8aROQEAyO77Ys+CPbLuvXVmhEy5/PVRtFJRaTywsTR+oLEZDRMAPA0hL43AwEDx9fWVI0eOSKlSpcx9K4ZB1lCZkJAgcXFx5ufjCqOenTxp3hed7gEAgIySE5Llt5m/yZq31qSby06vs2s2tJm59fXj+xaA5yLkpaEBq2rVqnL06FET9KwMLhcvXjRTFzC3zpVpHVWoUEH8/PzsLgoAwIUkxSXJ5imbZc2bayT6ULTZFlAoQG54+AZp9ngzKXldSbuLCACWIORloK13Ohl4UlKSJCcnW/IzExMTZeXKlXLzzTfTOpULWkcEPABA2nB38seT8u/B/5YLRy+YbYXLFJbm/2wuTR9rKiHFmf8VgHch5GXB2RXQqsClgUVDZXBwMCEPAIBcSklKkS3Ttsjy8cvlwpFL4S6sYpi0eb6Nud7OP5hfcwB4Jz79AACAW9HLHHbN2SVLRi2RqMhLE5cHhAdIh/EdpOnDTc08dwDgzQh5AADAbRzdclTmD5svB1YdMPdDw0Ol9fOt5XjF43JDzxvEL4CABwCEPAAA4PJiT8XKstHLZNNHm8SR4hD/EH+58akbpfVzrcUv1E/mzZtndxEBwGUQ8gAAgMvSQKfX3S0esVgunr5ottW/p750mthJwiqEpQ5gBgD4GyEPAAC4pFN/nJIfHvlB9q/Yb+6XblBaur3XTaq0q2J30QDApRHyAACAS0lOTDYTma8Yv0KS45MlIDRA2r/SXlo80UJ8/ZnEHACuhJAHAABcRtSuKPnuvu/kyMYj5n71ztXl1o9ulWJVitldNABwG4Q8AADgEtMibPj3Bln07CJJupgkwcWCpet7XaXhfQ3N/LUAgNwj5AEAAFtdOH5BZg+YLXsW7DH3q3WqJj2n9UwdWAUAkDeEPAAAYJt9y/fJN32/kQvHLoh/sL90fLOjNH+8ufj40noHAFeLkAcAACyXkpwiqyesluVjl5tpEkrVKyW9v+wtpeqWsrtoAOD2CHkAAMBSOt+dtt7tWXipe2bjgY2l+wfdzSiaAIBrR8gDAACWObHjhMy8faac+euM+If4S48Pe0jjAY3tLhYAeBRCHgAAsETk7Ej57v7vJOFCgpkS4Z4590hEwwi7iwUAHoeQBwAACnx6hFWvrZJlLy4z96u0r2KuvwsND7W7aADgkQh5AACgwCQnJsvcwXNly9Qt5n6zoc2ky6Qu4hfgZ3fRAMBjEfIAAECBiI+Ol6/u/srMf6dTInR7v5s0G9LM7mIBgMcj5AEAgHx3/sh5+aL7F3J823EzauZds+6SmrfWtLtYAOAVCHkAACBf6ciZ/+n4Hzm796wUiigk/X7sJ+WalrO7WADgNQh5AAAg35z8/aT8t9N/TUte8erF5f5F90vxqsXtLhYAeBVCHgAAyBdHNh6R6V2ny8VTF6V0/dJy38L7pEjZInYXCwC8DiEPAABcs4NrD8r0LtMl4XyClG9eXu796V4JKRFid7EAwCsR8gAAwDU59Muh1IBXpV0Vuef7eySoSJDdxQIAr0XIAwAAV+3QuvQBr++PfSWwUKDdxQIAr+ZrdwEAAIB7Orz+sEzvPN3Mh1e5bWUCHgC4CEIeAADIs+O/HjcteCbg3VxZ+s3tR8ADABdByAMAAHlyevdpE/DizsZJxVYVCXgA4GIIeQAAINeiD0ebefAuHLsgEQ0jLnXRLEzAAwBXQsgDAAC5Ensq1lyDd3bfWSlRo4SZBy+kONMkAICrIeQBAIArSryYKDNvnyknfz8pRcoVkfsX3S+FIwrbXSwAgCuGvMmTJ0uVKlUkODhYWrRoIevXr89x/3fffVdq1aolISEhUrFiRXnqqackLi7OsvICAOBtHCkO+e7+7+TgmoMSXCzYtOAVq1LM7mIBAFwx5M2aNUuGDx8uY8eOlc2bN0ujRo2kS5cucuLEiSz3nzFjhowcOdLsv3PnTpk6dap5jueff97ysgMA4C0WPbdIdn6zU/wC/aTP7D5Sul5pu4sEAHDVkDdp0iQZNGiQDBw4UOrWrStTpkyR0NBQmTZtWpb7r1mzRlq3bi39+vUzrX+dO3eWvn37XrH1DwAAXJ1176+TtW+vNes9P+0pVdpWsbtIAABXDXkJCQmyadMm6dix49+F8fU199euvfRlklGrVq3MMc5Q99dff8m8efOke/fulpUbAABv8cfcP2T+sPlm/ZbXbpEG/RrYXSQAQC74i02ioqIkOTlZIiIi0m3X+5GRkVkeoy14etxNN90kDodDkpKS5LHHHsuxu2Z8fLxZnKKjo81tYmKiWVyBsxyuUh5vQb1bjzq3HnVuPU+pcx1g5Zu+34g4RBo/2FhaPN3CZV+Tp9S5O6HOrUedWy/RBes8t2XxcWhassGRI0ekfPnypgtmy5YtU7c/99xzsmLFClm3bl2mY5YvXy733HOPvPLKK2aQlt27d8uwYcNMl8/Ro0dn+XPGjRsn48ePz/L6Pu0aCgAA0kuKTpI/nvtDEo4lSKF6haT6uOriG2D7WG0A4PViY2NNw9e5c+ckLCzM9UKedtfUkPX1119Lr169UrcPGDBAzp49K3PmzMl0TJs2beTGG2+UiRMnpm6bPn26PPLII3LhwgXT3TM3LXk6Kqe2COZUMVYn8kWLFkmnTp0kICDA7uJ4DerdetS59ahz67l7nScnJsvMW2fK/mX7pWiVojJwzUAJDXftP4q6e527I+rcetS59RJdsM41y4SHh18x5NnWXTMwMFCaNGkiS5YsSQ15KSkp5v7QoUOzTa4Zg5yfn5+5zS6rBgUFmSUjfaNc5c1y5TJ5A+rdetS59ahz67lrnS8avsgEvIBCAdL3+75StGxRcRfuWufujDq3HnXu3XUekMty2BbylE6foC13TZs2lebNm5s58GJiYsxom6p///6mS+eECRPM/dtuu82MyHn99dendtfUbpq63Rn2AADA1dn2n22y4YMNZv3O6XdKRIP0180DANyDrSGvT58+cvLkSRkzZowcO3ZMGjduLPPnz08djOXAgQPpWu5efPFF8fHxMbeHDx+WUqVKmYD36quv2vgqAABwf8d/PS4/PvajWW87tq3U7lXb7iIBANwx5Cntmpld90wdaCUtf39/MxG6LgAAIH/EnY2TWXfOkqSLSVKjaw1pO6at3UUCAFwDhsoCAMCLOVIcMnvAbDmz54wUrVxU7ph+h/j4+thdLADANSDkAQDgxX5+82fZ9f0u8Qv0k7u/vltCS7r2SJoAgCsj5AEA4KUO/HxAlr641Kx3e7+blGtazu4iAQDyASEPAAAvdPH0Rfm237fiSHZIg34N5IZBN9hdJABAPiHkAQDgZXRu2e8f/l7OHTgnxasXlx4f9jCjVwMAPAMhDwAAL7Pxw40S+V2k+Ab4yl2z7pKgsCC7iwQAyEeEPAAAvMixbcdkwfAFZr3Tm52kXBOuwwMAT0PIAwDASyTFJcm3934ryfHJUvPWmtJiWAu7iwQAKACEPAAAvMTiUYvl5I6TUiiikNw+7XauwwMAD0XIAwDAC+xZtEfWvbvOrPec1lMKlSpkd5EAAAWEkAcAgBdMlzDngTlmvengpnJd9+vsLhIAoAAR8gAA8PDpEn587Ec5f+S8lKxZUjq/1dnuIgEAChghDwAAD/bbzN/k969+F19/X7nzizslIDTA7iIBAAoYIQ8AAA914dgF+WnoT2a9zYttpFxTpksAAG9AyAMAwEO7ac4dPNdcj1emcRlp83wbu4sEALAIIQ8AAA/02/9+k8jZkeIb4Cu9Pu8lfgF+dhcJAGARQh4AAB7m/NHzMm/oPLN+8+ibJaJhhN1FAgBYiJAHAIAHdtOMOxMnZW8oKzeNvMnuIgEALEbIAwDAg/z+9e+ya84u002z52c96aYJAF6IkAcAgIfQQVZSR9N8vo1ENKCbJgB4I0IeAAAeYuGzCyXmRIyE1wmXm0bRTRMAvBUhDwAAD/DXkr9k67StIj4it39yu/gH+dtdJACATQh5AAC4ucTYRPnx0R/NerMhzaRiq4p2FwkAYCNCHgAAbm7FSyvkzJ4zElYhTDpM6GB3cQAANiPkAQDgxk7+flLWvr3WrHf/d3cJKhJkd5EAADYj5AEA4M5z4g2ZKylJKVKrZy2pdVstu4sEAHABhDwAANzU9hnbZf+K/eIf4i9d/9XV7uIAAFwEIQ8AADcUdzZOFj690KzfPPpmKVa5mN1FAgC4CEIeAABuaNmYZRJzPEZK1ioprZ5uZXdxAAAuhJAHAICbObrlqGyYvMGsd5/cXfwC/ewuEgDAhRDyAABwI44Uh8wdPNfc1r+nvlTrUM3uIgEAXAwhDwAAN7Jl2hY5vO6wBBYJlM5vd7a7OAAAF0TIAwDATcRGxcriEYvNervx7aRIuSJ2FwkA4IIIeQAAuInFoxbLxdMXJaJhhLR4ooXdxQEAuChCHgAAbuDQL4dkyydbzHr3f3cXX3++wgEAWeMbAgAAF5eSnGIGW1GNBzaWSq0r2V0kAIALI+QBAODitkzdIse2HpPgYsHS8Y2OdhcHAODiCHkAALiwuHNxsvTFpamDrRQqVcjuIgEAXBwhDwAAF7bylZUSezJWwmuHS9PBTe0uDgDADRDyAABwUaf+PCXr/rXOrHee1Fn8AvzsLhIAwA0Q8gAAcFGLnl0kKYkpUqNrDbmu23V2FwcA4CYIeQAAuKC/lvwlu+bsEh8/H9OKBwBAbhHyAABwMSlJKbLgyQVmvdnjzaRUnVJ2FwkA4EYIeQAAuJjNn2yWE7+dkJASIdJubDu7iwMAcDO2h7zJkydLlSpVJDg4WFq0aCHr16/Pcf+zZ8/K448/LmXLlpWgoCCpWbOmzJs3z7LyAgBQkOLOxsmy0ctSp0zQoAcAQF74i41mzZolw4cPlylTppiA9+6770qXLl1k165dUrp06Uz7JyQkSKdOncxjX3/9tZQvX172798vxYoVs6X8AADktxUvr5DYqFgJrxMuTR5tYndxAABuyNaQN2nSJBk0aJAMHDjQ3NewN3fuXJk2bZqMHDky0/66/fTp07JmzRoJCAgw27QVEAAAT3Dqj1Oy/r1LPVq6vNOFKRMAAO7VXVNb5TZt2iQdO3b8uzC+vub+2rVrszzm+++/l5YtW5rumhEREVK/fn157bXXJDk52cKSAwBQMBY+s9AMunJd9+ukRpcadhcHAOCmbGvJi4qKMuFMw1paej8yMjLLY/766y9ZunSp3HvvveY6vN27d8uQIUMkMTFRxo4dm+Ux8fHxZnGKjo42t3qMLq7AWQ5XKY+3oN6tR51bjzp3nzrfu3iv/PHDH+Lr7yu3vHEL71kecJ5bjzq3HnVuvUQXrPPclsXH4XA4xAZHjhwx19Rp10ttnXN67rnnZMWKFbJu3bpMx+ggK3FxcbJ3717x8/NL7fI5ceJEOXr0aJY/Z9y4cTJ+/PhM22fMmCGhoaH5+poAALgajhSH7Bq+S+L2xUn4reFS4eEKdhcJAOCCYmNjpV+/fnLu3DkJCwtzvZa88PBwE9SOHz+ebrveL1OmTJbH6Iiaei2eM+CpOnXqyLFjx0z3z8DAwEzHjBo1ygzukrYlr2LFitK5c+ccK8bqRL5o0SIzqIzzWkMUPOrdetS59ahz96jz7dO3y7Z92ySoaJDc9/F9ElqSP0LmBee59ahz61Hn1kt0wTp39kq8EttCngayJk2ayJIlS6RXr15mW0pKirk/dOjQLI9p3bq1aYHT/fT6PfXHH3+Y8JdVwFM6zYIuGekb5SpvliuXyRtQ79ajzq1HnbtunSfFJcnKcSvN+k0jb5KiZYpaUDrPxHluPercetS5d9d5QC7LYes8edrC9vHHH8vnn38uO3fulMGDB0tMTEzqaJv9+/c3LXFO+riOrjls2DAT7nQkTh14RQdiAQDAHa2fvF7OHTgnRcoXkRbDWthdHACAB7B1CoU+ffrIyZMnZcyYMabLZePGjWX+/Pmpg7EcOHAgtcVOaTfLBQsWyFNPPSUNGzY01/Rp4BsxYoSNrwIAgKtz8cxFWfXqKrPe/qX2EhDiGn8pBgC4N1tDntKumdl1z1y+fHmmbTpIyy+//GJByQAAKFirX18tcWfipFS9UtJoQCO7iwMA8BC2dtcEAMBbnTt4Ttb969JI0h1f7yi+fnwlAwDyB98oAADYYPmY5ZIcnyyVb64s1/W4zu7iAAA8CCEPAACLHd9+XLZ+vtWsd5rYSXx8fOwuEgDAgxDyAACw2JKRS0QcInV715XyzcvbXRwAgIch5AEAYKF9y/fJn/P+FF9/X+nwWge7iwMA8ECEPAAALOJIcciiZxeZ9SaPNpESNUrYXSQAgAci5AEAYJEdX+2QIxuPSGDhQGk7pq3dxQEAeChCHgAAFkhOSJalzy81662ebSWFSheyu0gAAA9FyAMAwAIbP9ooZ/46I4UiCknL4S3tLg4AwIMR8gAAKGDx0fGy8qWVZr3duHamuyYAAAWFkAcAQAH7eeLPEhsVKyVrlpTrH7re7uIAADwcIQ8AgAJ0/uh5+WXSL2a9w4QO4hfgZ3eRAAAejpAHAEABWj5uuSTGJkqFlhWk9h217S4OAMALEPIAACggUZFRsmXqFrPe6c1O4uPjY3eRAABegJAHAEABWTJqiTiSHVLr9lpS6aZKdhcHAOAlCHkAABSAg2sOSuTsSPHx9THX4gEAYBVCHgAA+czhcMiyUcvMeuMHG0upuqXsLhIAwIvkOuQdOXKkYEsCAICHOLfunBxae0j8Q/yl/fj2dhcHAOBlch3y6tWrJzNmzCjY0gAA4OZSklLk6PSjZv3Gp26UIuWK2F0kAICXyXXIe/XVV+XRRx+V3r17y+nTpwu2VAAAuKltn22T+EPxEhIeIq2fa213cQAAXijXIW/IkCHy66+/yqlTp6Ru3bryww8/FGzJAABwMwkxCbLypZVm/abnb5LgosF2FwkA4IX887Jz1apVZenSpfLBBx/InXfeKXXq1BF///RPsXnz5vwuIwAAbmHtpLUScyxGAiMC5YZHbrC7OAAAL5WnkKf2798v3377rRQvXlx69uyZKeQBAOCNYk7EyJo315j1sveVFb9AP7uLBADwUnlKaB9//LE8/fTT0rFjR9mxY4eUKsWQ0AAAqBUvr5CECwlS5oYyUqx1MbuLAwDwYrkOeV27dpX169ebrpr9+/cv2FIBAOBGTu8+LZumbDLrt0y4RX6/+LvdRQIAeLFch7zk5GQz8EqFChUKtkQAALiZpS8sNVMn1OhaQ6q0ryK/zyPkAQDcIOQtWrSoYEsCAIAbOrzhsOz4coeIj0jHNzraXRwAAHI/hQIAAEjP4XDI4ucWm/VG9zeSiIYRdhcJAABCHgAAV2v3T7tl3/J94hfkJ+1fbm93cQAAMAh5AABchZTkFFk84lIrXvMnmkvRSkXtLhIAAAYhDwCAq/Drf3+VE7+dkOBiwdJmVBu7iwMAQCpCHgAAeZR4MVGWjV5m1m96/iYJKRFid5EAAEhFyAMAII/Wv79eog9FS1jFMGnxRAu7iwMAQDqEPAAA8uDi6YuyesJqs66DrfgH53o2IgAALEHIAwAgD1a9tkrizsZJ6QalpeF9De0uDgAAmRDyAADIpTN7z5iumkonPvf142sUAOB6+HYCACCXlr6wVJITkqVqh6pSo2sNu4sDAECWCHkAAOTCkY1H5Lf//SbiI9JpYifx8fGxu0gAAGSJkAcAwBU4HA5Z+MxCs67X4ZW9vqzdRQIAIFuEPAAAruCPH/+Q/Sv2i1+Qn9zyyi12FwcAgBwR8gAAyEFKUoosfm6xWb/xyRulaKWidhcJAIAcEfIAAMjB5qmbJSoySkJKhshNo26yuzgAAFwRIQ8AgGwkXEiQ5WOXm/W2Y9pKcNFgu4sEAMAVEfIAAMjGmrfWSMzxGClRo4Q0fayp3cUBACBXCHkAAGTh/NHzsmbiGrPeYUIH8Qv0s7tIAAC4T8ibPHmyVKlSRYKDg6VFixayfv36XB03c+ZMM09Rr169CryMAADvot00E2MTpULLClLnH3XsLg4AAO4T8mbNmiXDhw+XsWPHyubNm6VRo0bSpUsXOXHiRI7H7du3T5555hlp06aNZWUFAHiHEztOyJapW8x657c6M/E5AMCt2B7yJk2aJIMGDZKBAwdK3bp1ZcqUKRIaGirTpk3L9pjk5GS59957Zfz48VKtWjVLywsA8HyLRywWR4pD6txZRyq2qmh3cQAAyBN/sVFCQoJs2rRJRo0albrN19dXOnbsKGvXrs32uJdeeklKly4tDz30kKxatSrHnxEfH28Wp+joaHObmJhoFlfgLIerlMdbUO/Wo86tR53n3b5l++TPuX+Kr7+v3PzSzXmuO+rcetS59ahz61Hn1kt0wTrPbVlsDXlRUVGmVS4iIiLddr0fGRmZ5TGrV6+WqVOnytatW3P1MyZMmGBa/DJauHChaTF0JYsWLbK7CF6JercedW496jx3HMkO2TV8l1kv0bmErNu9TmT31T0XdW496tx61Ln1qHPvrvPY2FjXD3l5df78ebn//vvl448/lvDw8Fwdo62Ees1f2pa8ihUrSufOnSUsLExcJZHrydOpUycJCAiwuzheg3q3HnVuPeo8bzZ/vFm27d8mwcWD5b6p90loybz/MZA6tx51bj3q3HrUufUSXbDOnb0SXTrkaVDz8/OT48ePp9uu98uUKZNp/z179pgBV2677bbUbSkpKebW399fdu3aJdWrV093TFBQkFky0jfKVd4sVy6TN6DerUedW486v7K4s3GycuxKs95ufDspWqboNT0fdW496tx61Ln1qHPvrvOAXJbD1oFXAgMDpUmTJrJkyZJ0oU3vt2zZMtP+tWvXlu3bt5uums7l9ttvl/bt25t1baEDAOBqrHxlpcRGxUp4nXAmPgcAuDXbu2tqV8oBAwZI06ZNpXnz5vLuu+9KTEyMGW1T9e/fX8qXL2+urdN59OrXr5/u+GLFipnbjNsBAMitU3+eknXvrTPrXSZ1Eb8AJj4HALgv20Nenz595OTJkzJmzBg5duyYNG7cWObPn586GMuBAwfMiJsAABSURc8skpTEFKnRrYbU6FrD7uIAAODeIU8NHTrULFlZvnx5jsd+9tlnBVQqAIA3+GvxX7Lr+13i4+djWvEAAHB3NJEBALxWSlKKLHhqgVlv9ngzCa+du5GbAQBwZYQ8AIDX2vTxJjnx2wkJKREi7ca2s7s4AADkC0IeAMBrp0xYNnpZ6pQJGvQAAPAEhDwAgFda8dIKuXjqopSqW4opEwAAHoWQBwDwOqf+OCXr319v1ru800V8/fk6BAB4Dr7VAABexeFwmMFWdNCV63pcJ9U7V7e7SAAA5CtCHgDAq+yas0v+nPen+Ab4Sue3O9tdHAAA8h0hDwDgNRJiEmT+sPlmvdWzrSS8FlMmAAA8DyEPAOA1Vr6yUs4dOCdFKxeVm1+42e7iAABQIAh5AACvEBUZJWvfXmvWu73XTQJCA+wuEgAABYKQBwDwisFW5j0+T1ISU6TmrTWl1u217C4SAAAFhpAHAPB4v838TfYu3Sv+wf7S9b2udhcHAIACRcgDAHi0+Oh4Wfj0QrPe5oU2UrxqcbuLBABAgSLkAQA82rKxy+TC0QtS4roSZkRNAAA8HSEPAOCxjm07JuvfW2/Wu0/uLv5B/nYXCQCAAkfIAwB4JEeKQ+YNmWdu6/auK9U7Vbe7SAAAWIKQBwDwSFs/2yoH1xyUwMKB0uWdLnYXBwAAyxDyAAAeJ/ZUrCwesdistx3XVsLKh9ldJAAALEPIAwB4HB1NMzYqVkrXLy0t/tnC7uIAAGApQh4AwKPsWbhHtn2+TcRH5LZPbhO/AD+7iwQAgKUIeQAAj5EQkyA/PvqjWdcWvAotKthdJAAALEfIAwB4jGVjlsnZfWelaKWicssrt9hdHAAAbEHIAwB4hMMbDsu6d9eZ9R5TephRNQEA8EaEPACA20tOSJbvH/rezInX4N4Gcl236+wuEgAAtiHkAQDc3spXVsqJ7SckNDyUOfEAAF6PkAcAcGtHNx+VVa+tMuvd/91dCpUqZHeRAACwFSEPAODW3TRnPzBbHMkOqdu7rtTrXc/uIgEAYDtCHgDAba14ecWlbpqlQqX75O52FwcAAJdAyAMAuKUjm47I6gmrzXqPf/egmyYAAJcR8gAAbifxYqJ8d/93pptmvbvrSd276tpdJAAAXAYhDwDgdhaPWCxRO6OkcJnCdNMEACADQh4AwK3sXrBb1r+/3qz3/LSnmTYBAAD8jZAHAHAbsadiZc7AOWa92ePNpEbXGnYXCQAAl0PIAwC4BYfDIT8+8qNcOHpBwmuHS6c3O9ldJAAAXBIhDwDgFrZM2yI7v90pvv6+cucXd0pAaIDdRQIAwCUR8gAALu/k7yflpyd+MuvtX24vZW8oa3eRAABwWYQ8AIDLT5fwdZ+vJeliklTrWE1aP9fa7iIBAODSCHkAAJe24KkFcuK3E1KodCG54793iI+vj91FAgDApRHyAAAua8dXO2TTR5vM+h3T7zDz4gEAgJwR8gAALun07tPyw6AfzHrrka2leqfqdhcJAAC3QMgDALicxNhE+fIfX0r8uXip2KqitH+pvd1FAgDAbRDyAAAuNx/e3MFz5fivx811eHd9eZf4BfjZXSwAANwGIQ8A4FL0Grxt/9kmPn4+ctesuySsfJjdRQIAwK0Q8gAALuPw+sMyf9h8s95hQgep0q6K3UUCAMDtuETImzx5slSpUkWCg4OlRYsWsn79+mz3/fjjj6VNmzZSvHhxs3Ts2DHH/QEA7uH80fMy685ZkpyQLHXurCOtnmlld5EAAHBLtoe8WbNmyfDhw2Xs2LGyefNmadSokXTp0kVOnDiR5f7Lly+Xvn37yrJly2Tt2rVSsWJF6dy5sxw+fNjysgMA8kdSXJLMumOWnD98XsJrh0vPT3uKjw/z4QEA4JYhb9KkSTJo0CAZOHCg1K1bV6ZMmSKhoaEybdq0LPf/4osvZMiQIdK4cWOpXbu2fPLJJ5KSkiJLliyxvOwAgPwZaOWHR36Qw+sOS3DxYOn7Q18JCguyu1gAALgtW0NeQkKCbNq0yXS5TC2Qr6+5r610uREbGyuJiYlSokSJAiwpAKCgrH17rfz631/NQCu9v+otJWrweQ4AwLXwFxtFRUVJcnKyREREpNuu9yMjI3P1HCNGjJBy5cqlC4ppxcfHm8UpOjra3Gow1MUVOMvhKuXxFtS79ahz67l6nf85909Z9Nwis97xrY5S8eaKLltWT6lzT0SdW486tx51br1EF6zz3JbFx6H9ZGxy5MgRKV++vKxZs0ZatmyZuv25556TFStWyLp163I8/vXXX5c333zTXKfXsGHDLPcZN26cjB8/PtP2GTNmmG6hAAB7xO6Old0v7JaU+BQp2amkVBhSgevwAAC4Qi/Gfv36yblz5yQsLMw1W/LCw8PFz89Pjh8/nm673i9TpkyOx7711lsm5C1evDjbgKdGjRplBnZJ25LnHKwlp4qxOpEvWrRIOnXqJAEBAXYXx2tQ79ajzq3nqnV+dt9Z+fyxz03Aq9qxqtw9+26PmfDcVevck1Hn1qPOrUedWy/RBevc2SvxSmwNeYGBgdKkSRMzaEqvXr3MNucgKkOHDs32OG29e/XVV2XBggXStGnTHH9GUFCQWTLSN8pV3ixXLpM3oN6tR517d51fPHNRvuz5pcQci5GIhhHS55s+EhTqeQOtuFKdewvq3HrUufWoc++u84BclsPWkKe0lW3AgAEmrDVv3lzeffddiYmJMaNtqv79+5sunRMmTDD333jjDRkzZozpbqlz6x07dsxsL1y4sFkAAK4rKf7SVAlRO6OkSPki0m9uP0bSBAAgn9ke8vr06SMnT540wU0Dm06NMH/+/NTBWA4cOGBG3HT68MMPzaicd911V7rn0Xn29Po7AIBrSklKkW/6fiP7V+yXwCKBcu+8eyWsgmt0mwcAwJPYHvKUds3MrnumDqqS1r59+ywqFQAgvzhSHPLDoB8k8rtI8Qv0kz7f9TFdNQEAgAdOhg4A8Gw6iPPCZxbK1s+2io+vj9w16y6p1qGa3cUCAMBjEfIAAAVq5Ssr5Zd3fjHrt0+7XWr3qm13kQAA8GiEPABAgVn9+mpZPuZSt/su73aRxgMa210kAAA8HiEPAFAgfn7zZ1kyaolZb/9Ke7lx2I12FwkAAK9AyAMA5LufJ/4si0csNuvtXmonN79ws91FAgDAaxDyAAD53oK3+LnLAW98O2k7uq3dRQIAwKu4xBQKAADPGEVz6QtLZfWE1eZ+23Ftpe0YAh4AAFYj5AEA8mUevHlD58nGDzea+x1e7yA3jbjJ7mIBAOCVCHkAgGuSnJgscwbOke1fbBfxEenxYQ9p+mhTu4sFAIDXIuQBAK5afHS8fHX3V7JnwR7x9feVXv/pJQ36NrC7WAAAeDVCHgDgqkQfjpYZ3WfI8V+PS0BogNz15V1Ss0dNu4sFAIDXI+QBAPLs+PbjJuBFH4qWQhGFpN+P/aRc03J2FwsAABDyAAB5teuHXfLtvd9KwvkECa8dLvf+dK8Uq1LM7mIBAIDLCHkAgFxPkbDqtVWybPQyEYdI5baVpc93fSSkeIjdRQMAAGkQ8gAAV5QQk2BG0Pz9q9/N/aZDmkrXd7uKX4Cf3UUDAAAZEPIAADmKioySr3p/JSd+OyG+Ab7SfXJ3aTKoid3FAgAA2SDkAQCy9ev0X+XHx36UxJhEM8DK3d/cLZVaV7K7WAAAIAeEPABAJomxifLTsJ9kyydbzP2qHarKndPvlMJlCttdNAAAcAWEPABAOkc2HpFv7/tWTu06JeIj0m5cO2nzQhvx9fO1u2gAACAXCHkAACMlKUVWTVglK19aadYLly0sd/z3DqnWoZrdRQMAAHlAyAMAyMnfT8qcB+fI4XWHzf26vevKrVNulZASTI8AAIC7IeQBgBdLTkiW1a+vllWvrjLrQUWDzOiZDfo1EB8fH7uLBwAArgIhDwC81MG1B+WHQT/IyR0nzf2at9aU7v/uLkUrFrW7aAAA4BoQ8gDAy1w4fkGWjFwiWz/bau6HlgqVbu93k3p316P1DgAAD0DIAwAvkZyYLBsmb5DlY5dLfHS82dZ4YGPpNLGThJYMtbt4AAAgnxDyAMDDORwO2TV7lyx/cbmc+uOU2Va2SVnp/kF3qXBjBbuLBwAA8hkhDwA82ME1B2X3qN2yLXKbuR8aHiq3vHaLXP/g9cx7BwCAhyLkAYAHOrTukKwYv0J2/7Tb3PcP8ZeWT7eU1s+2lqCwILuLBwAAChAhDwA8yKFfDsmKl/4Odz5+PlLilhLS7+N+UqJyCbuLBwAALEDIAwA350hxyJ8//SlrJq6R/Sv2p4a7Rv0bScvnWsraXWulSLkidhcTAABYhJAHAG4q8WKi/Pa/32TtpLWpc935BvhKw/saSpsX2kiJ6iUkMTFRZJfdJQUAAFYi5AGAmzm957Rs/HCjbJm2ReLOxJltgUUCpcmjTeTGYTdKWIUwu4sIAABsRMgDADeQFJckkXMiZcvULfLX4r9EHJe2F6taTJoObipNHmkiwUWD7S4mAABwAYQ8AHDha+10IJXt/9su27/Yntpqp2p0rSHNHm8mNbrVYCoEAACQDiEPAFxs4vLD6w7Lji93yO9f/S7Rh6JTH9NumI0HNpbGDzSW4tWK21pOAADgugh5AOACwe7IhiOpwe7cgXOpj+m1drV71pYG9zaQap2q0WoHAACuiJAHADa4ePqi7Fm0R/Ys2CO75++WC0cvpD4WWDhQat1eS+reXVdqdKkh/sF8VAMAgNzjNwcAsEBKcopprdu9YLfsmb9HDq8/bK65cwooFCC1brsc7LrWkICQAFvLCwAA3BchDwAKaA47DXUHfj4gB1cflINrDkrc2b8HTlGl65eW6l2qm1BX6aZKtNgBAIB8wW8UAJAP19SdP3L+71D380E5svGIpCSmpNsvuFiwVOtYTap3rW66YTKfHQAAKAiEPADIA+1ieeavM3J081E5uuWoHNtyzKzHnozNtG/hsoVNC50uFVtXlDKNyoivPwOnAACAgkXIA4BswtzZ/WclameUREVGycmdJ8368V+PS8L5hEz7+/j5SKk6pUyY00WDXbEqxcTHx8eW8gMAAO9FyAPg1YOhnD983rTMmWXvGTmz58ylYLcrSpIuJmV5nF47V7pBaSl7Q1kpc30ZKXt9WXOfwVIAAIArIOQB8NiWuJiTMeZaOQ1yeht9ONrcntt/Ts7uPWta6jJeN5eWX6CflKxZUsLrhJtFW+pK1Stlbul2CQAAXJVLhLzJkyfLxIkT5dixY9KoUSN5//33pXnz5tnu/9VXX8no0aNl3759ct1118kbb7wh3bt3t7TMAKyXnJhs5peLjYqVi6cu3TqXC8cupAtzOu9cSlL2Ac7JN8DXdKssXq24WYpVLSbhtS8FOt1OmAMAAO7G9pA3a9YsGT58uEyZMkVatGgh7777rnTp0kV27dolpUuXzrT/mjVrpG/fvjJhwgS59dZbZcaMGdKrVy/ZvHmz1K9f35bXACD3rWvJsckSfSja3Mafi5e4c3HmNj7673XnrTPQOUNdxikIrshHpHBEYSlSrsilpfyl27CKYamhTu/7+hHkAACA57A95E2aNEkGDRokAwcONPc17M2dO1emTZsmI0eOzLT/v/71L+natas8++yz5v7LL78sixYtkg8++MAcCyB3Q/5rK1dyQrIkxydLUnySudX7znVzm/bxNOuJsYl/LzHpbxNiEjI9lnabOES2y/arL7yPSEjxEAkND01dQkqGSOEyhdMHufJhUiiikPgF+OVn1QEAALg8W0NeQkKCbNq0SUaNGpW6zdfXVzp27Chr167N8hjdri1/aWnL3+zZs8VdxZyIkbhDcWawB/+Ay2+JI/0v5JZtS7Pdim2Wv74025ISk+TcxnOyK3GX+Pn6mVYmszgu36ZZ9LiM2wpqPw1fjuRLt1dacrufDjDiDGnOIJe2LqymXSCDigZJcNFgcxsUln7deRta8u8g51yCiwfT8gYAAOCqIS8qKkqSk5MlIiIi3Xa9HxkZmeUxet1eVvvr9qzEx8ebxSk6OtrcJiYmmsUV/PzGzxL5fqTof7DeXtkr3s7H10f8gvzMQCN66x/kf2k9zX3fQN/U7f4h/hJYKFD8Q/0lMPTybaE0tyFZ35cAkdUbVkvnHp0lMDDwqsqanJJsFuSO83POVT7vvAF1bj3q3HrUufWoc+slumCd57YstnfXLGh67d748eMzbV+4cKGEhoaKKzh67Kj4FcmiS1ma6bWynGsr7aasHnYek900Xc7t2Tye4/E+V1HOq/k5Vzg+3c/LZTkzHeNzKeSkrvtcXve9vH650SjdPhn3901/XNr9U58jq+fO8BzO59Y518Tv0txrWd03x+v65SXL+5ePS3usDjLi4+8jPgGXF//L23Sfq5AiKRInOVwnp/ODZ5gj3DfIVxYvXnxVPw9XT7u1w1rUufWoc+tR59ajzr27zmNjM/xi5YohLzw8XPz8/OT48ePptuv9MmXKZHmMbs/L/toVNG33Tm3Jq1ixonTu3FnCwsLEFSR2SjQnT6dOnSQggHm2rPxLCPVuLercetS59ahz61Hn1qPOrUedWy/RBevc2SvRpUOedtdq0qSJLFmyxIyQqVJSUsz9oUOHZnlMy5YtzeNPPvlk6jatfN2elaCgILNkpG+Uq7xZrlwmb0C9W486tx51bj3q3HrUufWoc+tR595d5wG5LIft3TW1lW3AgAHStGlTMzeeTqEQExOTOtpm//79pXz58qbbpRo2bJi0bdtW3n77benRo4fMnDlTNm7cKP/3f/9n8ysBAAAAAPvZHvL69OkjJ0+elDFjxpjBUxo3bizz589PHVzlwIEDZsRNp1atWpm58V588UV5/vnnzWToOrImc+QBAAAAgAuEPKVdM7Prnrl8+fJM23r37m0WAAAAAEB6TDYFAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB7EJebJs5LD4TC30dHR4ioSExMlNjbWlCkgIMDu4ngN6t161Ln1qHPrUefWo86tR51bjzq3XqIL1rkzwzgzTXa8LuSdP3/e3FasWNHuogAAAADAVWWaokWLZvu4j+NKMdDDpKSkyJEjR6RIkSLi4+MjrpLINXQePHhQwsLC7C6O16DerUedW486tx51bj3q3HrUufWoc+tFu2Cda3TTgFeuXDnx9c3+yjuva8nTyqhQoYK4Ij15XOUE8ibUu/Woc+tR59ajzq1HnVuPOrcedW69MBer85xa8JwYeAUAAAAAPAghDwAAAAA8CCHPBQQFBcnYsWPNLaxDvVuPOrcedW496tx61Ln1qHPrUefWC3LjOve6gVcAAAAAwJPRkgcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkGeRV199VVq1aiWhoaFSrFixLPc5cOCA9OjRw+xTunRpefbZZyUpKSnH5z19+rTce++9Zu4Ofd6HHnpILly4UECvwn0tX75cfHx8slw2bNiQ7XHt2rXLtP9jjz1madndWZUqVTLV3+uvv57jMXFxcfL4449LyZIlpXDhwvKPf/xDjh8/blmZ3dm+ffvMZ0DVqlUlJCREqlevbi4YT0hIyPE4zvO8mzx5sjm/g4ODpUWLFrJ+/foc9//qq6+kdu3aZv8GDRrIvHnzLCuru5swYYI0a9ZMihQpYr4be/XqJbt27crxmM8++yzTOa11j9wZN25cpvrT8zcnnOP5/32pi34fZoVzPO9Wrlwpt912m5lEXOtr9uzZ6R7XYUrGjBkjZcuWNd+hHTt2lD///DPfvw+sQsiziP6S1bt3bxk8eHCWjycnJ5uAp/utWbNGPv/8c/MPWE+2nGjA27FjhyxatEh+/PFHcwI/8sgjBfQq3JcG7KNHj6ZbHn74YfPLcNOmTXM8dtCgQemOe/PNNy0rtyd46aWX0tXfE088keP+Tz31lPzwww/mF4YVK1bIkSNH5M4777SsvO4sMjJSUlJS5KOPPjKfC++8845MmTJFnn/++Ssey3mee7NmzZLhw4ebAL1582Zp1KiRdOnSRU6cOJHl/vqZ3rdvXxPAt2zZYkKKLr/99pvlZXdH+jmgv+j+8ssv5rsuMTFROnfuLDExMTkep3/8THtO79+/37Iye4J69eqlq7/Vq1dnuy/n+LXTPzinrW8915X+7pgdzvG8iYmJMZ/XGsqyot977733nvneXLdunRQqVMh8tusfn/Pr+8BSOromrPPpp586ihYtmmn7vHnzHL6+vo5jx46lbvvwww8dYWFhjvj4+Cyf6/fff9eRUR0bNmxI3fbTTz85fHx8HIcPHy6gV+AZEhISHKVKlXK89NJLOe7Xtm1bx7Bhwywrl6epXLmy45133sn1/mfPnnUEBAQ4vvrqq9RtO3fuNOf52rVrC6iUnu3NN990VK1aNcd9OM/zpnnz5o7HH3889X5ycrKjXLlyjgkTJmS5/9133+3o0aNHum0tWrRwPProowVeVk904sQJ85mwYsWKPH/XInfGjh3raNSoUa735xzPf/qZXL16dUdKSkqWj3OOXxsRcXz33Xep97Wey5Qp45g4cWK630mCgoIc//vf//Lt+8BKtOS5iLVr15ruDREREanb9C8B0dHR5i/y2R2jXTTTtkRp07Kvr6/5CwSy9/3338upU6dk4MCBV9z3iy++kPDwcKlfv76MGjVKYmNjLSmjp9Dumdr18vrrr5eJEyfm2AV506ZN5q/0eh47afefSpUqmfMdeXfu3DkpUaLEFffjPM8d7W2h52nac1Q/c/V+dueobk+7v/PznXP66s9pdaXzWi9dqFy5slSsWFF69uyZ7Xcpsqbd1LRbW7Vq1UyvIb2kJDuc4/n/OTN9+nR58MEHTbfC7HCO55+9e/fKsWPH0p3HRYsWNd0vszuPr+b7wEr+dhcAl+iJlTbgKed9fSy7Y/T6hLT8/f3NF192x+CSqVOnmi+gChUq5Lhfv379zAeoftH9+uuvMmLECHMtyLfffmtZWd3ZP//5T7nhhhvMOandeTQ8aJeSSZMmZbm/nreBgYGZrlvVfwuc03m3e/duef/99+Wtt97KcT/O89yLiooy3euz+rzW7rJ5+XznnM477Y785JNPSuvWrc0fJLJTq1YtmTZtmjRs2NCEQv03oN329ZfgK33uQ8wvtnrJiNajfmaPHz9e2rRpY7pf6rWRGXGO5y+9Vuzs2bPywAMPZLsP53j+Onb5XM3LeXw13wdWIuRdg5EjR8obb7yR4z47d+684sXKsPY9OHTokCxYsEC+/PLLKz5/2usbtaVVL8bt0KGD7Nmzxwxq4Y3yUufaT91Jv4g0wD366KNmIIWgoCALSuu95/nhw4ela9eu5noOvd4uJ5zncBd6bZ4GjZyuD1MtW7Y0i5P+8lunTh1zverLL79sQUndW7du3dJ9dmvo0z8E6femXneHgv9DtL4H+oe37HCO40oIedfg6aefzvGvLEq7OeRGmTJlMo3G4xxRUB/L7piMF3ZqVzgdcTO7YzzN1bwHn376qek+ePvtt+f55+kXnbOFxFt/+b2W817rT89RHQVS/wqZkZ632v1B/4KZtjVP/y14yzmdH3Wug9W0b9/efOn/3//9X55/Hud59rRLq5+fX6YRX3M6R3V7XvZH1oYOHZo6wFheWyoCAgJMl3E9p5F3+nlcs2bNbOuPczz/6OApixcvznNPCs7xa1Pm8rmq563+odNJ7zdu3Djfvg+sRMi7BqVKlTJLftC/xug0CxranF0wdWQlHTmpbt262R6jvwxrf+AmTZqYbUuXLjXdWZy/pHm6vL4Heq2thrz+/fubD8S82rp1q7lN+wHgba7lvNf60/7qGbsZO+l5rO/LkiVLzNQJSrsN6rUgaf9i6W3yUufagqcBT+tSz3Wt77ziPM+etkZr3eo5qqMHKv3M1fsaQrKi564+rt0MnfTz3ZvP6bzQz20dlfe7774z0+HoqMh5pV2qtm/fLt27dy+QMno6vfZLW/bvv//+LB/nHM8/+rmt35E64npecI5fm6pVq5pgpuexM9TpuBg6xkV2I+NfzfeBpewe+cVb7N+/37FlyxbH+PHjHYULFzbrupw/f948npSU5Khfv76jc+fOjq1btzrmz59vRn8cNWpU6nOsW7fOUatWLcehQ4dSt3Xt2tVx/fXXm8dWr17tuO666xx9+/a15TW6g8WLF5sRlXTExoy0XrV+tS7V7t27zeibGzdudOzdu9cxZ84cR7Vq1Rw333yzDSV3P2vWrDEja+r5vGfPHsf06dPNOd2/f/9s61w99thjjkqVKjmWLl1q6r5ly5ZmwZVpfdaoUcPRoUMHs3706NHUJe0+nOfXZubMmWbEtc8++8yMcvzII484ihUrljo68v333+8YOXJk6v4///yzw9/f3/HWW2+Zzx4duVBHkd2+fbuNr8J9DB482IwiuHz58nTndGxsbOo+Getcv2sXLFhgPns2bdrkuOeeexzBwcGOHTt22PQq3MvTTz9t6ls/E/T87dixoyM8PNyMbKo4xwuGjsyo338jRozI9Bjn+LU7f/586u/f+rvgpEmTzLr+jq5ef/1181mu34O//vqro2fPnmZ06osXL6Y+xy233OJ4//33c/19YCdCnkUGDBhgTqiMy7Jly1L32bdvn6Nbt26OkJAQ82GqH7KJiYmpj+u+eox+6DqdOnXKhDoNjjrdwsCBA1ODIzLTumrVqlWWj2m9pn1PDhw4YH7RLVGihPkHrL88P/vss45z585ZXGr3pF86OoS2/nKmXzx16tRxvPbaa464uLhs61zph+mQIUMcxYsXd4SGhjruuOOOdCEF2dMhtbP6nEn79zzO8/yhX/L6y1hgYKAZQvuXX35JNyWFfuan9eWXXzpq1qxp9q9Xr55j7ty5NpTaPWV3Tuv5nl2dP/nkk6nvT0REhKN79+6OzZs32/QK3E+fPn0cZcuWNfVXvnx5c1//IOTEOV4wNLTpub1r165Mj3GOX7tll3+Pzrg461WnURg9erSpT/0+1D+YZnwvdGoo/SNGbr8P7OSj/7O7NREAAAAAkD+YJw8AAAAAPAghDwAAAAA8CCEPAAAAADwIIQ8AAAAAPAghDwAAAAA8CCEPAAAAADwIIQ8AAAAAPAghDwAAAAA8CCEPAAAAADwIIQ8AgGuQnJwsrVq1kjvvvDPd9nPnzknFihXlhRdesK1sAADv5ONwOBx2FwIAAHf2xx9/SOPGjeXjjz+We++912zr37+/bNu2TTZs2CCBgYF2FxEA4EUIeQAA5IP33ntPxo0bJzt27JD169dL7969TcBr1KiR3UUDAHgZQh4AAPlAv05vueUW8fPzk+3bt8sTTzwhL774ot3FAgB4IUIeAAD5JDIyUurUqSMNGjSQzZs3i7+/v91FAgB4IQZeAQAgn0ybNk1CQ0Nl7969cujQIbuLAwDwUrTkAQCQD9asWSNt27aVhQsXyiuvvGK2LV68WHx8fOwuGgDAy9CSBwDANYqNjZUHHnhABg8eLO3bt5epU6eawVemTJlid9EAAF6IljwAAK7RsGHDZN68eWbKBO2uqT766CN55plnzCAsVapUsbuIAAAvQsgDAOAarFixQjp06CDLly+Xm266Kd1jXbp0kaSkJLptAgAsRcgDAAAAAA/CNXkAAAAA4EEIeQAAAADgQQh5AAAAAOBBCHkAAAAA4EEIeQAAAADgQQh5AAAAAOBBCHkAAAAA4EEIeQAAAADgQQh5AAAAAOBBCHkAAAAA4EEIeQAAAADgQQh5AAAAACCe4/8B3xt8C0k+jr4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + mx.np.exp(-x))\n",
    "\n",
    "X = mx.np.arange(-10, 10.1, 0.1)\n",
    "Y = sigmoid(X)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.plot(X.asnumpy(), Y.asnumpy(), label='Sigmoid', color='purple')\n",
    "plt.title('Plot of Sigmoid function')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1856a",
   "metadata": {},
   "source": [
    "Now that we have the pieces, let's see how they are used.\n",
    "\n",
    "### Forward-Propagation\n",
    "\n",
    "Forward-propagating an input is straightforward. We work through each layer of our network calculating the outputs for each neuron. All of the outputs from one layer become inputs to the neurons on the next layer. Below is a function named `forward_propagate()` that implements the forward-propagation for a row of data from our dataset with our neural network.\n",
    "\n",
    "You can see that a neuron’s output value is stored in the neuron with the name `output`. You can also see that we collect the outputs for a layer in an array named `new_inputs` that becomes the array inputs and is used as inputs for the following layer. The function returns the outputs from the last layer also called the output layer.\n",
    "\n",
    "Let’s put all of these pieces together and test out the forward-propagation of our network. We define our network inline with one hidden neuron that expects 2 input values and an output layer with two neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69d005a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate_tensor(network_weights, row):\n",
    "    inputs = mx.nd.array(row)\n",
    "\n",
    "    for weights in network_weights:\n",
    "        inputs = mx.nd.concat(inputs, mx.nd.ones((1,)), dim=0)\n",
    "\n",
    "        activations = mx.nd.dot(weights, inputs)\n",
    "\n",
    "        inputs = SML.transfer(activations)\n",
    "\n",
    "    return inputs\n",
    "sml.add_to_class(sml, 'forward_propagate_tensor', forward_propagate_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "901561f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorized forward output: [0.6629970073699951, 0.725316047668457]\n"
     ]
    }
   ],
   "source": [
    "network_weights = [\n",
    "    mx.nd.array([[0.13436424, 0.84743373, 0.76377462]]),\n",
    "    mx.nd.array([\n",
    "        [0.25506903, 0.49543509],\n",
    "        [0.44949106, 0.65159297]\n",
    "    ])\n",
    "]\n",
    "\n",
    "row = [1.0, 0.0]\n",
    "\n",
    "output = sml.forward_propagate_tensor(network_weights, row)\n",
    "\n",
    "print(\"Tensorized forward output:\", output.asnumpy().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ca61d",
   "metadata": {},
   "source": [
    "Running the example propagates the input pattern [1, 0] and produces an output value that is printed. Because the output layer has two neurons, we get a list of two numbers as output. The actual output values are just nonsense for now, but next, we will start to learn how to make the weights in the neurons more useful.\n",
    "\n",
    "[0.6629970129852887, 0.7253160725279748]  \n",
    "Sample Output from Forward-Propagate Input Through a Network.\n",
    "\n",
    "## 15.2.3 Backpropagate Error\n",
    "\n",
    "The backpropagation algorithm is named for the way in which weights are trained. Error is calculated between the expected outputs and the outputs forward-propagated from the network. These errors are then propagated backward through the network from the output layer to the hidden layer, assigning blame for the error and updating weights as they go. The math for backpropagating error is rooted in calculus, but we will remain high level in this section and focus on what is calculated and how rather than why the calculations take this particular form.\n",
    "\n",
    "This part is broken down into two sections:\n",
    "\n",
    "1. Transfer Derivative.  \n",
    "2. Error Backpropagation.\n",
    "\n",
    "### Transfer Derivative\n",
    "\n",
    "Given an output value from a neuron, we need to calculate its slope. We are using the sigmoid transfer function, the derivative of which can be calculated as follows:\n",
    "\n",
    "$$\n",
    "\\text{derivative} = \\text{output} \\times (1.0 - \\text{output})\n",
    "\\tag{15.3}\n",
    "$$\n",
    "\n",
    "Below is a function named `transfer_derivative()` that implements this equation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "314d45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "sml.add_to_class(sml, 'transfer_derivative', transfer_derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831c0bf",
   "metadata": {},
   "source": [
    "Now, let’s see how this can be used.\n",
    "\n",
    "### Error Backpropagation\n",
    "\n",
    "The first step is to calculate the error for each output neuron; this will give us our error signal (input) to propagate backwards through the network. The error for a given neuron can be calculated as follows:\n",
    "\n",
    "$$\n",
    "\\text{error} = (\\text{expected} - \\text{output}) \\times \\text{transfer\\_derivative(output)} \\tag{15.4}\n",
    "$$\n",
    "\n",
    "Where expected is the expected output value for the neuron, output is the output value for the neuron and transfer_derivative() calculates the slope of the neurons output value, as shown above. This error calculation is used for neurons in the output layer. The expected value is the class value itself. In the hidden layer, things are a little more complicated.\n",
    "\n",
    "The error signal for a neuron in the hidden layer is calculated as the weighted error of each neuron in the output layer. Think of the error traveling back along the weights of the output layer to the neurons in the hidden layer. The backpropagated error signal is accumulated and then used to determine the error for the neuron in the hidden layer, as follows:\n",
    "\n",
    "$$\n",
    "\\text{error} = \\left(\\sum_j \\text{weight}_{j} \\times \\text{error}_{j}\\right) \\times \\text{transfer\\_derivative(output)} \\tag{15.5}\n",
    "$$\n",
    "\n",
    "Where error_j is the error signal from the jth neuron in the output layer, weight_j is the weight that connects the kth neuron to the current neuron and output is the output for the current neuron. Below is a function named `backward_propagate_error()` that implements this procedure. You can see that the error signal calculated for each neuron is stored with the name `delta`.\n",
    "\n",
    "You can see that the layers of the network are iterated in reverse order, starting at the output and working backwards. This ensures that the neurons in the output layer have delta values calculated first that neurons in the hidden layer can use in the subsequent iteration. I chose the name delta to reflect the change the error implies on the neuron (e.g. the weight delta).\n",
    "\n",
    "You can see that the error signal for neurons in the hidden layer is accumulated from neurons in the output layer where the hidden neuron number j is also the index of the neurons weight in the output layer neuron[weights][j].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07999e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate_error_tensor(network_weights, activations, expected):\n",
    "    deltas = [None] * len(network_weights)\n",
    "\n",
    "    output = activations[-1]\n",
    "    error = expected - output\n",
    "    delta = error * sml.transfer_derivative(output)\n",
    "    deltas[-1] = delta\n",
    "\n",
    "    for i in reversed(range(len(network_weights) - 1)):\n",
    "        next_weights = network_weights[i + 1][:, :-1]\n",
    "        next_delta = deltas[i + 1]\n",
    "\n",
    "        error = mx.nd.dot(next_weights.T, next_delta)\n",
    "        delta = error * sml.transfer_derivative(activations[i + 1])\n",
    "        deltas[i] = delta\n",
    "\n",
    "    return deltas\n",
    "sml.add_to_class(sml, 'backward_propagate_error_tensor', backward_propagate_error_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a19cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 delta: [-0.0005345838144421577]\n",
      "Layer 1 delta: [-0.14618642628192902, 0.07717236876487732]\n"
     ]
    }
   ],
   "source": [
    "network_weights = [\n",
    "    mx.nd.array([[0.13436424, 0.84743374, 0.76377462]]),\n",
    "    mx.nd.array([\n",
    "        [0.25506903, 0.49543509],\n",
    "        [0.44949106, 0.65159297]\n",
    "    ])\n",
    "]\n",
    "\n",
    "activations = [\n",
    "    mx.nd.array([1.0, 0.0]),\n",
    "    mx.nd.array([0.71056688]),\n",
    "    mx.nd.array([0.62133597, 0.65736935])\n",
    "]\n",
    "\n",
    "expected = mx.nd.array([0.0, 1.0])\n",
    "\n",
    "deltas = sml.backward_propagate_error_tensor(network_weights, activations, expected)\n",
    "\n",
    "for i, delta in enumerate(deltas):\n",
    "    print(f\"Layer {i} delta:\", delta.asnumpy().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f02ed",
   "metadata": {},
   "source": [
    "Running the example prints the network after the backpropagation of error is complete. You can see that error values are calculated and stored in the neurons for the output layer and the hidden layer.\n",
    "\n",
    "```json\n",
    "[{'output': 0.7105668883115941,\n",
    "  'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
    " {'delta': -0.0005348048046610517}]\n",
    "\n",
    "[{'output': 0.6218359615555266,\n",
    "  'weights': [0.2550690257394217, 0.49543508709194095],\n",
    "  'delta': -0.14619064683582808},\n",
    " {'output': 0.6573693455986976,\n",
    "  'weights': [0.4494910647887381, 0.651592972722763],\n",
    "  'delta': 0.0771723774346327}]\n",
    "```\n",
    "\n",
    "Sample Output from Backpropagate Error Through a Network.\n",
    "\n",
    "\n",
    "## 15.2.4 Train Network\n",
    "\n",
    "The network is trained using stochastic gradient descent. Gradient descent was introduced and described in Section 8.1.2. The procedure involves multiple iterations of exposing a training dataset to the network and for each row of data forward-propagating the inputs, backpropagating the error and updating the network weights. This part is broken down into two sections:\n",
    "\n",
    "1. Update Weights  \n",
    "2. Train Network\n",
    "\n",
    "### Update Weights\n",
    "\n",
    "Once errors are calculated for each neuron in the network via the backpropagation method above, they can be used to update weights. Network weights are updated as follows:\n",
    "\n",
    "$$\n",
    "\\text{weight} = \\text{weight} + \\text{learning rate} \\times \\text{error} \\times \\text{input}\n",
    "\\tag{15.6}\n",
    "$$\n",
    "\n",
    "Where `weight` is a given weight, `learning rate` is a parameter that you must specify, `error` is the error calculated by the backpropagation procedure for the neuron and `input` is the input value that caused the error. The same procedure can be used for updating the bias weight, except there is no input term, or input is the fixed value of 1.0.\n",
    "\n",
    "Learning rate controls how much to change the weight to correct for the error. For example, a value of 0.1 will update the weight 10% of the amount that it possibly could be updated. Small learning rates are preferred that cause slower learning over a large number of training iterations. This increases the likelihood of the network finding a good set of weights across all layers rather than the fastest set of weights that minimize error (called premature convergence).\n",
    "\n",
    "Below is a function named `update_weights()` that updates the weights for a network given an input row of data, a learning rate and assume that a forward and backward propagation have already been performed. Remember that the input for the output layer is a collection of outputs from the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e6f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights_tensor(network, row, learning_rate):\n",
    "    inputs = mx.nd.array(row[:-1])\n",
    "\n",
    "    for i, layer in enumerate(network):\n",
    "        if i != 0:\n",
    "            inputs = mx.nd.array([neuron['output'] for neuron in network[i - 1]])\n",
    "\n",
    "        for neuron in layer:\n",
    "            weights = neuron['weights']\n",
    "            delta = neuron['delta']\n",
    "            \n",
    "            weight_update = learning_rate * delta * inputs\n",
    "            weights[:-1] = weights[:-1] + weight_update\n",
    "\n",
    "            weights[-1] = weights[-1] + learning_rate * delta\n",
    "\n",
    "            neuron['weights'] = weights\n",
    "\n",
    "sml.add_to_class(sml, 'update_weights_tensor', update_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e9493ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network, train_data, learning_rate, n_epochs, n_outputs, test_data=None):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        sum_error = 0.0\n",
    "\n",
    "        for row in train_data:\n",
    "            activations = sml.forward_propagate_tensor(network, mx.nd.array(row[:-1]))\n",
    "            outputs = activations[-1]\n",
    "\n",
    "            expected = mx.nd.zeros(n_outputs)\n",
    "            expected[int(row[-1])] = 1.0\n",
    "\n",
    "            sum_error += mx.nd.sum(mx.nd.square(expected - outputs)).asscalar()\n",
    "\n",
    "            deltas = sml.backward_propagate_error_tensor(\n",
    "                [neuron['weights'] for layer in network for neuron in layer],\n",
    "                activations,\n",
    "                expected\n",
    "            )\n",
    "            sml.update_weights_tensor(network, row, learning_rate)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(f\"Epoch={epoch}, lrate={learning_rate:.3f}, error={sum_error:.3f}\")\n",
    "\n",
    "        train_losses.append(sum_error)\n",
    "\n",
    "        if test_data:\n",
    "            sum_error = 0.0\n",
    "            for row in test_data:\n",
    "                activations = SML.forward_propagate_tensor(network, mx.nd.array(row[:-1]))\n",
    "                outputs = activations[-1]\n",
    "                expected = mx.nd.zeros(n_outputs)\n",
    "                expected[int(row[-1])] = 1.0\n",
    "                sum_error += mx.nd.sum(mx.nd.square(expected - outputs)).asscalar()\n",
    "            test_losses.append(sum_error)\n",
    "\n",
    "    return network, train_losses, test_losses\n",
    "sml.add_to_class(sml, 'train_network', train_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4ef7839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1              X2              Y\n",
      "2.781083600     2.550537003     0\n",
      "1.465489372     2.362125076     0\n",
      "3.396561688     4.400293529     0\n",
      "1.388070190     1.850220317     0\n",
      "3.064072320     3.005305973     0\n",
      "7.627531214     2.759262235     1\n",
      "5.332441248     2.088626775     1\n",
      "6.922596716     1.771063670     1\n",
      "8.675418651     -0.242068655    1\n",
      "7.673756466     3.508563011     1\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    [2.7810836, 2.550537003, 0],\n",
    "    [1.465489372, 2.362125076, 0],\n",
    "    [3.396561688, 4.400293529, 0],\n",
    "    [1.38807019, 1.850220317, 0],\n",
    "    [3.06407232, 3.005305973, 0],\n",
    "    [7.627531214, 2.759262235, 1],\n",
    "    [5.332441248, 2.088626775, 1],\n",
    "    [6.922596716, 1.77106367, 1],\n",
    "    [8.675418651, -0.242068655, 1],\n",
    "    [7.673756466, 3.508563011, 1]\n",
    "]\n",
    "\n",
    "print(f\"{'X1':<15} {'X2':<15} {'Y'}\")\n",
    "\n",
    "for row in dataset:\n",
    "    print(f\"{row[0]:<15.9f} {row[1]:<15.9f} {int(row[2])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f749ffc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAGGCAYAAADGq0gwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6KElEQVR4nO3dB3hUZb7H8X+A0IOIKEWaBVSqLogLsjaaDeXKtSwKAqIugg0VYVWaDcu1ouBSdRVhLVi4KiIIKEWKoFhBQYpUCwQInbnP79WTOwkpM2GSc3Ly/TzPEDJzMvPO/GeS+c3bkiKRSMQAAAAAAKFQzO8GAAAAAAASh5AHAAAAACFCyAMAAACAECHkAQAAAECIEPIAAAAAIEQIeQAAAAAQIoQ8AAAAAAgRQh4AAAAAhAghDwAAAABChJAHANmYOXOmJSUlua9B8u9//9tOPvlkS05OtooVK8b98z/99JO7X48//rgVNd59Hz9+fPp5gwcPducVlftbUML8uAJA0BHyABQ5esOrN5/eqXTp0lavXj3r06ePbdq0KSG38d5777k3uYn23XffWbdu3eyEE06wUaNG2b/+9a8Cb0M8duzYYYMGDbKGDRtauXLl7KijjrJTTz3Vbr31Vlu/fr0VRgr9l112mVWtWtVKlixpxxxzjHXo0MHefPPNfL3dINQzP+j5HP16LF++vB1//PH23//93/bGG2/YwYMH83zdEyZMsKeeesqCIC0tzdUvaB8aAQinEn43AAD8MnToUDvuuONs9+7d9umnn9qIESPcG+mvvvrKypYte1jXret57rnnEv6mXG8Q9ab36aefthNPPNGXNsRq3759dtZZZ7lgeu2119rNN9/sQt/XX3/t3nz/13/9l1WvXt0KEwVWPW/q1q1rN954o9WuXdt+/fVX91h36tTJXnnlFevcuXO+3HZe6qn27dq1y/X6BlmpUqVs9OjR7v9q7+rVq+3dd991Qe+cc86xt99+2ypUqBD39ep5ptfzbbfdZkEIeUOGDHH/130CgPxEyANQZF1wwQXWrFkz9/+ePXu6XqYnnnjCvaH8+9//bkG0efNm9zUvwzQL2ltvvWVLlizJMvgoWO/du9cKk9dff90FPAUPhYfo4HTXXXfZ1KlTXbANgv3797sPA9TTqJ7qoCtRooRdc801Gc574IEHbNiwYTZgwAC7/vrrbdKkSb61DwAKG4ZrAsCfzjvvPPd11apVOR732muvWdOmTa1MmTJWuXJl9+b0559/zjD8TD0uEj0MLTfPP/+8NWjQwPVqqIerd+/etnXr1vTL69Sp43qS5Oijj3bXmV2vTqxt0HBPDf3UbZ5++um2cOHCQ45RT5yCTaVKlVxgUDB+5513cr0/P/74o/t65plnHnKZrie6Z0bt1TC9NWvW2MUXX+z+f+yxx6bfh2XLlrn6aMineqcUsqL99ttvduedd1qjRo3cz+q6FeK/+OILS5T77rvPPQZjx47Nsmesffv2ru3Rgfy6666zKlWquPvbpEkTe/HFF7OdH5lTLXKqZ/R1aGiidx3ffPPNIXPydIy+V09ZZgpTCoW///57+nmfffaZnX/++XbEEUe43u2zzz7b5syZc8jPqidcbdb91O2/8MILlgj9+/e3du3audfc8uXL08/XBzEXXXSRe53ovuo277//fjtw4ED6Meot+9///V93X73HS68h0QcMAwcOdK9j3Tc9r/72t7/Zxx9/fEgbJk6c6I5LSUlxzys9x9STHk2vU/UW1qxZ07VHveyPPPJI+lBT1UGvWVFvnteeMA6/BRAM9OQBQKZQoh697OjNcvfu3d0b2ocfftjN4dMbPr3xVa+Vetg0jE/zzaZNm+YWSYmF3uzpzV+bNm2sV69e9v3337vho3qjr+tWqNAb+JdeeskmT57sLlOYady4cZbXF0sbFJS2b9/ujtUbzkcffdTNNVu5cmV6iNHQSoU0BS694dab4f/85z/WsWNHN19KQy6zozAmavO9996ba9DVG3QFMw3xVFvUA6h5krrNe+65x66++mrXvpEjR1rXrl2tRYsWbritqM3qObz88svdeaqLgoZCicLO4Q4LXbFihQu7PXr0cG/2c6MhhwoZP/zwg7sPapOCisKaAoHmJMZTi1jqOW7cONdDesMNN7igoUCaeT7bFVdcYf369XM1VO9jNJ2nQHXkkUe672fMmOHqoYCjDxeKFSvmbkNh+5NPPrHmzZunB3D9nEKMnsfqRdTxCreJ0KVLF/vwww/dfdfcWe91qOd/37593Ve1VaEtNTXVHnvsMXeMnjPbtm2zdevW2ZNPPunO07Gi4zQ8VD326iXUYz9mzBgX1BcsWODmjYpuU8e0bt3ahTb59ttv3WvSq6GGYep5pg96VKdatWrZ3LlzXWjesGGDe93qsdFrVq9tvWZUW8nu9QsAhy0CAEXMuHHjIvr199FHH0W2bNkSWbt2bWTixImRo446KlKmTJnIunXr3HEff/yxO05fZe/evZFjjjkm0rBhw8iuXbvSr2/KlCnuuIEDB6af17t3b3deLDZv3hwpWbJkpF27dpEDBw6knz98+HB3HWPHjk0/b9CgQe48tTs32bVh1apV7nzd399++y39/Lffftud/+6776af17p160ijRo0iu3fvTj/v4MGDkZYtW0bq1q2b4+2npaVFTjrpJHedtWvXjnTr1i0yZsyYyKZNmw459tprr3XHPfTQQ+nn/f77764eSUlJrj6e7777zh2rx8Kj9kU/dt79LFWqVGTo0KGH3Hc9BzI/pjnxHpsnn3wyEounnnrKHf/yyy+nn6fnT4sWLSLly5ePpKamxl2L3OpZoUIF91zK6rLo+6s2NG3aNMNxCxYscMe99NJL6TVWfdu3b+/+H13T4447LtK2bdv08zp27BgpXbp0ZPXq1ennffPNN5HixYvH9BpQ7cuVK5ft5UuWLHHXc/vtt2doR2Y33nhjpGzZshmeqxdddJF77mW2f//+yJ49ezKcp+dblSpVIj169Eg/79Zbb3WPq47Pzv333+/av3z58gzn9+/f3z0Ga9ascd/rNZv5eQsA+YXhmgCKLPWa6RN2DbG66qqr3Kf86iVTr1VWFi1a5Ibg3XTTTRnmOWnYmLY00NCwvPjoo4/c8DEN91JviUc9DBoeltfrzc2VV16Z3msjGq4m6j3yhkCqh0S9P+rp+OWXX9xJC42ox0O9W9HDVDPTcFYN9/N6jNT7ouGL1apVc4uw7Nmz55Cf0dxIj3pFTzrpJNeTpzZ4dJ4u89op6rnyHjv1CKqNqqeO/fzzzw/zkfqj50di6cXzFknR6pvRczvVI3fLLbe4xWdmzZoVVy1ioYVfvCGBOdFtLV68OL3nWjTfTY/hpZde6r5funSpq6/mUuqx9Gq/c+dO16s1e/Zs10uox1pzEdWzqx4szymnnOKeI4ng9b7pORj93PJ4z009ZupVU49rbooXL+6Gporuh57r6oHUUOTo54ueZ7rP6tHLjnpodduqn/c46aTfL3p89FgBQEFjuCaAIktznDT8S4s+aGiZAkF0yMrMm8ek4zJTyNO8pLzI7nr1JlRLyWc1fyoRot+UixcyvDlZGmoYiUTcXDSdsqLQm10oFs130tBDnXQ/pk+f7uaFDR8+3F2mxTU8Cs6ZQ4qOqVGjxiFDPXV+9Nwxb8VRzWvUnMrouVk5Db+NlTd/MDpo5ET3VStwZn4+Kfx4l8dTi1h4Q1dzoyGtGuaoYPfPf/7T1VhBRUMzvfupgCdaFTU7GgqpoK6hqbqvmen5rLB7uBSKMwdsDSPWEGB9COEF8Oh2xULzI//nf/7HhcLoBXOiH0d9oKNhrHps9DzXsFR94KB5ih49Vl9++WW2AdtbLAkAChIhD0CRpTlF3uqaRZF6M7KiN/3izefSgibZ9crkto1D5jl6mtOmOUkKr5pzFx3ysmtPbu2Uhx56yAVRXb8W4NB8NAUs9Y4ezj5r0SHem3+WH2K5j7mJ7t3KieYnqudJ4UUhb/78+W7BG2/OmXiPmea3efPTsuphy6o3NtG0BUL0c01zGjUHToFUq51q0RV9QKAeuLvvvjumer/88stufqR6INXTrL0OVQPNs43u4dT56tVUb+X777/vTpqXqDmh3iI6ur22bdu6uY5Z8eYRAkBBIuQBQIy8hUS0KIq3EqdH53mXSyyraWZ1vQo/Hg3hVK+Uhn3lRTxtyIrXFg0zzGsbsqJeKr0x9968J2p7g3PPPdctnhFNgUAroB4uvVFXz5RWdVSPoTeEMKeaqndHASC6N88bShj9XCmoemYesqleKj3n1KOnlTO1obtH9REFqZxqr94rhUuv5y+arjsRtNCM7ruClLdXpIaQavN5LdLjyWpV3OweMz1f9PzWdUQf461em7lHXY+NTqqnHjct6qMPFRQ89ViptzG310gi6wcAuWFOHgDESL1++mRfqztG92Do032tuKe5eR7NI5PoLRCyozeHeiP5zDPPZOi5UWDR0LPo641HPG3Iiu6rVojUG1qtEpjZli1bcvx5bV+guUmZaaiiVrzMathrXqkXJnOvl4Yg5jRnMF5a/VThQvMGNX8rM60AOWXKFPf/Cy+80DZu3Jhhbzf9zLPPPusConqiCrqemefv6TF79dVX3eOkrR+86xetqKnwoqG13nDJrGqv61Avr1Y2VW+gR68H9X4dLu2Tp8dVodQbEur1ekbXWx+IaKhuZrpPWQ3fzOo6NH903rx5GY5TvaMpsHsrYnq/AzR8Uz+X1f1VrbznioK0dx4A5Dd68gAgRurR0pA2baGgN+laVMPbQkH7b91+++0Z3iSLFtrQm2C9qdTiLtn1hmi5dYUIzfW55JJLXC+I3rRqq4bMm0THKp425DRvsVWrVm5vMC0Eo94P3We9qdXS9DntQ6fFKtQzovvz17/+1YUbLSSifeb0BjmRe4QppGjonmrTsmVLN6xSw0Gje0YPl4KGrvfBBx9022Wo/uqRUxD44IMP3HxDb/8+bWOgcKwhgVrkRM8P9R5p6X0tqR/rAi6Jrmd0gFfP5xNPPOHmGeq+ZQ4z2mJAc9G0d6MeV81JU2jWXnLq4Xv33XfdsXre6v5rCKh6ubwwq59Tb2Ys9DMaQinaBkIfBGgvRv282qk9BD2qr3qDNV9Qj4V6yNTbl9XQVj1mCtqag6jXkp6D6pHT80W9eBo6rA9R1AuoD2/q16+fIdQq0GtRFvXca26o2qX7piGs3vxKDfdUW3WdqrduU4u16LmimmuPPPUmq8dT16/2qGdYQ4obNmzoTgCQcPm2bicABHwLhYULF+Z4XOYtFDyTJk2KnHbaaW55/kqVKkWuvvrq9G0XPFpy/eabb44cffTRbguAWH7dasuEk08+OZKcnOyWcu/Vq5db1j1aPFsoZNcGb1n9xx577JCfyWqJ9x9//DHStWvXSNWqVV3bjj322MjFF18cef3113O8/ZUrV7ptJf7617+6rSdKlCjh2qJl7WfMmBHTMvpnn312pEGDBoecr2XxdT0eLZt/xx13RKpVq+a2XTjzzDMj8+bNcz+v0+FuoRBt+vTpkUsvvTTDferQoYPb9iCatoro3r17pHLlym6LDG1FEX278dYiL/XM6v56Ro0a5S5LSUnJsCVI5u0LLrvsMrfFg57vetyvuOIK9xhEmzVrltuWQffz+OOPj4wcOTLmx9XbPsM7aRuEOnXqRDp16uSeY5m3xpA5c+a455VqXb169Ui/fv0iU6dOPeT1umPHjkjnzp0jFStWTN/KQ7QthLbr0Pe6X3o9aysUtSV6ywXdvrY2Ua1132rVquW2atiwYUOG9mzfvj0yYMCAyIknnuiOU821zcjjjz/uts7wzJ07N/1xYjsFAPkpSf8kPjoCAAAAAPzAnDwAAAAACBFCHgAAAACECCEPAAAAAEKEkAcAAAAAIULIAwAAAIAQIeQBAAAAQIgU6s3QDx48aOvXr3ebymozVAAAAAAII+18t337dqtevboVK1YsvCFPAa9mzZp+NwMAAAAACsTatWutRo0a4Q156sHz7miFChX8bg7MbN++ffbhhx9au3btLDk52e/mIBPqE2zUJ7ioTbBRn2CjPsFFbQpXfVJTU10Hl5eBQhvyvCGaCniEvOA8GcuWLevqwS+L4KE+wUZ9govaBBv1CTbqE1zUpnDWJ5Zpaiy8AgAAAAAhQsgDAAAAgBAh5AEAAABAiBTqOXkAAAAAEuPAgQNuHhj8oXl3xYsXT8h1EfIABI7+vjD/GwCAgtt/bcOGDbZ161a/m1LkVaxY0apWrXrYe4AT8gAEytixZr16mY0YYdajh9+tAQAg/DZv3uw22T7mmGPcao6HGzCQt6CdlpbmaiHVqlWzw0HIAxCogNezp37R/fFVCHoAAOQfBTrtv1alShU76qij/G5OkVamTBn3VUFPgftwsPAKgMAFPPGCns4HAAD5w5sDph48+M+rw+HOjSTkAQhcwPMQ9AAAKBgM0QxXHQh5AAIZ8DwEPQAAgPgQ8gAENuB5CHoAABQeQduFISkpyd566y0rSgh5AHz7A6BVNHMLeB4dp+OD9ocDAAD8P30gW758wX0wu3HjRrv55pvt+OOPt1KlSlnNmjWtQ4cONn36dAvKqpkDBw50q2VqYZU2bdrYihUr8v12CXkAfKF98LRNQqxDz3Wcjmf/PAAAgj1CZ+/eghmB89NPP1nTpk1txowZ9thjj9myZcvsgw8+sHPPPdd69+5tQfDoo4/aM888YyNHjrTPPvvMypUrZ+3bt7fdu3fn6+0S8gD4RtsjjB6de9DT5TqO7RQAAAgmP1bJvummm9xQzAULFlinTp2sXr161qBBA+vbt6/Nnz8/25+7++673bFayVI9gPfdd1+G1Sy/+OILFxRTUlKsQoUKLkguWrTIXbZ69WrXU3jkkUe6wKbbe++997LtxXvqqafs3nvvtUsvvdQaN25sL730kq1fvz7fh4+yTx4AX3nBLbu5eQQ8AAAK9yrZkui/47/99pvrtXvwwQdd2MqsYsWK2f6swtv48eOtevXqrvfv+uuvd+f169fPXX711VfbaaedZiNGjHBbTCxdutSS/xxKpB7CvXv32uzZs93tfvPNN1Ze41OzsGrVKjecVEM0PUcccYSdccYZNm/ePLvqqqssvxDyAAQ26BHwAAAIxyrZksi/5z/88IPrKTv55JPj/tl77703/f916tSxO++80yZOnJge8tasWWN33XVX+nXXrVs3/Xhdpl7DRo0aue/VE5gdBTzRRvPR9L13WX5huCaAQA7dJOABABBsfq6SrYCXV5MmTbIzzzzTqlat6nrhFPoU3jwa7tmzZ0/XAzds2DD78ccf0y+75ZZb7IEHHnA/P2jQIPvyyy8tiAh5AAIX9EqWJOABABBkfq+Srd41zcf77rvv4vq5efPmueGYF154oU2ZMsWWLFli99xzjxuC6Rk8eLB9/fXXdtFFF7lFXerXr2+TJ092lyn8rVy50rp06eKGejZr1syeffbZLG9LIVI2bdqU4Xx9712WXwh5AAJFwW7HDgIeAABB5vcq2ZUqVXKrVD733HO2c+fOQy7funVrlj83d+5cq127tgt2CmgKi1pMJTMtzHL77bfbhx9+aJdddpmNGzcu/TJt0/CPf/zD3nzzTbvjjjts1KhRWd7Wcccd58Jc9HYOqampbpXNFi1aWH4i5AEIHLZJAAAg+PxeJVsB78CBA9a8eXN744033P5z3377rduyILsQpVCnoZmag6dhmDrW66WTXbt2WZ8+fWzmzJku/M2ZM8cWLlxop5xyirv8tttus6lTp7pFVT7//HP7+OOP0y879H4nueM1vPOdd95xPX9du3Z1C7507NjR8hMLrwAAAAAodKtka9ETBS2tsKketQ0bNtjRRx/ttjzQyphZueSSS1wPnYLcnj173JBMbaGgIZqi1TR//fVXF8Y0rLJy5cquJ2/IkCHucoVKrbC5bt06t73C+eefb08++WS2bdRiLuppvOGGG1zvYqtWrdyqoKVLl7b8RMgDAAAAUChXya5WrZoNHz7cnWJdpOXRRx91p2jqcZOSJUvaq6++mu11ZTf/LjvqzRs6dKg7FSSGawIAAAA4LKySHSyEPAAAAACHjVWyg4PhmgAAAAASQsGuSxcWUfMbPXkAAAAAEoaA5z9CHgAAAACECCEPAAAAAEKEkAcAAAAAIULIAwAAAIAQIeQBAAAAQIgEJuQNGzbM7Qjv7TYPAAAAAIcrKSnJ3nrrLStKAhHyFi5caC+88II1btzY76YAAAAAKCQ2btxoN998sx1//PFWqlQpq1mzpnXo0MGmT59uQfDmm29au3bt7KijjnJhc+nSpUVjM/QdO3bY1VdfbaNGjbIHHnjA7+YAAAAAiMeKFWbbt2d/eUqKWd26Cb/Zn376yc4880yrWLGiPfbYY9aoUSPbt2+fTZ061Xr37m3fffed+W3nzp3WqlUru+KKK+z6668vsNv1PeSpABdddJG1adMm15C3Z88ed/Kkpqa6ryqmTvCfVwfqEUzUJ9ioT3BRm2CjPsFGfYLLq0kkErGDBw+6U9xWrLBiJ5+c62EHFbgSHPR69erlesfmz59v5cqVSz//lFNOsW7dumW4P9H3r3///m745rp166xq1arWuXNnu++++yz5z13cv/jiC+vbt68tWrTIXX/dunVtxIgR1qxZM1u9erXrOZwzZ47t3bvX6tSpY4888ohdeOGFWbZRnVleIM3cjqzoMtVDtfGOy8tryNeQN3HiRPv888/dcM1YPPzwwzZkyJBDzv/www+tbNmy+dBC5NW0adP8bgJyQH2CjfoEF7UJNuoTbNQnmEqUKGG7d+92o+sUWuJVfONGS4nhuJ0bN9qBKlUsUX7//XfXY3fvvffagQMH0jt/PMWKFctw3q5du9K/L1mypD377LNWrVo1+/rrr92aIAp4t956q7tcoU/TyDTks3jx4rZs2TLX0aSf/8c//uHC1pQpU1ywVG+hgmDm289Mj697HHbuzPFY1UBtnT17tu3fvz/DayctLS34IW/t2rXugVSjS5cuHdPPDBgwwKVqjx4gjbvVONcKFSrkY2sRKz3pVdO2bdumfxqC4KA+wUZ9govaBBv1CTbqE+zafPzxx+69ePny5WN+T55BVA9azoeVM0vg+3WFK/V4NWnSJKYcUKZMmfTjhg4dmn5+w4YNXY/epEmTXG+e/Pzzz9avXz/XcyennXZa+vEbNmywyy67zFq0aOG+j3VNET2+3uOQU3sVuNXWs846ywXM6NdObkEyECFv8eLFtnnzZvvLX/6Sfp5SuFLr8OHDXVrWHYumyZQ6ZaY7zS+NYKEmwUZ9go36BBe1CTbqE2zUJ7jUE6WeL53iFuPPuOvOy/Xn0GbvemNpd7Go4xTonnnmGfvxxx9dD5t6zBS8vMvVqXTDDTfYK6+84qaUXX755XbCCSe4y2655RY3TFThS5d16tQppqDnXXdu7dVlum96rXhZyHvtxPP68W11zdatW7uuT60w452UljVuVf/PHPAAAAAAQDRPTmEo3sVV5s2b5/KG5tBpyOWSJUvsnnvuyTBUdfDgwW4Yp9YNmTFjhtWvX98mT57sLuvZs6etXLnSunTp4rKM8ouGfgaNbyEvJSXFdY9Gn9R9qeVF9X8AAAAAyEqlSpWsffv29txzz7l5bplt3bo1y5+bO3eu1a5d2wU7BTSFRS2mklm9evXs9ttvd2t/aHjmuHHj0i/TdDHNzdP2CHfccYfbJSBoArFPHgAAAADEQwFP072aN29ub7zxhq1YscK+/fZbNxTTmzOXmULdmjVr3AKQGq6pY71eOtGiJ3369LGZM2e68KdVNLVIpFbsFC3SogVfVq1a5RaQ1JxG77Ks/Pbbb26U4jfffOO+//7779332t8v1FsoRNODCQAAAAC50QboCloPPvig61HToihHH320NW3a1G15kJVLLrnE9dApyGkNEA3J1IIrGqIpmjL266+/WteuXW3Tpk1WuXJl15PnrfCvUKkt4LRYi+bxnX/++fbkk09m28Z33nnHunfvnv79VVdd5b4OGjQo/TZDH/IAAAAAFCLa6DyRx8VJ2yBo0UadshOJRDJ8/+ijj7pTNPXQedsrvPrqq9leV7zz77Rfn04FjZAHAAAAIG+0wfny5Wbbt+cc8BK8ETpyRsgDAAAAkHcEuMBh4RUAAAAACBFCHgAAAACECCEPAAAAAEKEkAcAAAAUcQcPHvS7CbDE1YGFVwAAAIAiav/+/VasWDFbv36922NOWwgkJSX53awiJxKJ2N69e23Lli2uHqqD9uTLK0IeAAAAUITVqlXLhQsFPfirbNmyrh4KeoQ8AAAAAHmSnJzsgoV69Q4nWODwFC9e3EqUKJGQnlRCHgAAAFDEKVgo7OmEwo+FVwAAAAAgRAh5AAAAABAihDwAAAAACBFCHgAAAACECCEPAAAAAEKEkAcAAAAAIcIWCgAAAEB+W7HCbPv27C9PSTGrW7cgW4QQI+QBAAAA+R3w6tXL/bjlywl6SAiGawIAAAD5KacevLwcB+SCkAcAAAAAIULIAwAAAIAQIeQBAAAAQIgQ8gAAAAAgRAh5AAAAABAihDwAAAAACBFCHgAAAJCftNF5Io8DcsFm6AAAAEB+0gbn2ug8p33wFPDYCB0JQsgDAAAA8hsBDgWI4ZoAAAAAECKEPAAAAAAIEUIeAAAAAIQIIQ8AAAAAQoSQBwAAAAAhQsgDAAAAgBAh5AEAAABAiBDyAAAAACBECHkAAAAAECKEPAAAAAAIEUIeAAAAAIQIIQ8AAAAAQoSQBwAAAAAhQsgDAAAAgBAh5AEAAABAiBDyAAAAACBECHkA0u3b53cLAAAAcLgIeQCcsWPNypf/4ysAAAAKrxJ+NwCA/xTsevY0i0T++Co9evjdKgAAABS6nrwRI0ZY48aNrUKFCu7UokULe//99/1sElCkA554QY8ePQAAgMLJ15BXo0YNGzZsmC1evNgWLVpk5513nl166aX29ddf+9ksoMgGPA9BDwAAoPDydbhmhw4dMnz/4IMPut69+fPnW4MGDXxrF1CUA56HoZsAAACFU2Dm5B04cMBee+0127lzpxu2CSD/vPxyzgHPQ9ADAAAofHwPecuWLXOhbvfu3Va+fHmbPHmy1a9fP8tj9+zZ406e1NRU93Xfvn3uBP95daAeweTVZcCAfVa6dOw/17ev2VVXmSUn51/bwOsnyKhNsFGfYKM+wUVtCld94qlTUiSS22f5+Wvv3r22Zs0a27Ztm73++us2evRomzVrVpZBb/DgwTZkyJBDzp8wYYKVLVu2gFoMAAAAAAUrLS3NOnfu7HKTFq0MdMjLrE2bNnbCCSfYCy+8EFNPXs2aNe2XX37J9Y6iYOgThmnTplnbtm0tmW6fQNdn0qRk69Mn5yGbSUlmw4ebXXNNQbay6OL1E1zUJtioT7BRn+CiNoWrPso+lStXjink+T5cM7ODBw9mCHLRSpUq5U6Z6U7zxAwWahJsqk337snpc+6yCnoKeKNHm3Xv7kcLizZeP8FFbYKN+gQb9QkualM46hNPjXwNeQMGDLALLrjAatWqZdu3b3fDLmfOnGlTp071s1lAkeEtppI56HkBj8VWAAAACh9fQ97mzZuta9eutmHDBjviiCPcxugKeOqSBOBP0CPgAQAAFG6+hrwxY8b4efMA/uQFul69zEaMIOABAAAUZoGbkwfAHwp2XbqwTQIAAEBhV8zvBgAIDgIeAABA4UfIAwAAAIAQYbgmAAAAkGgrVpht35795SkpZnXrFmSLUIQQ8gAAAIBEB7x69XI/bvlygh7yBcM1AQAAgETKqQcvL8cBcSLkAQAAAECIEPIAAAAAIEQIeQAAAAAQIoQ8AAAAAAgRQh4AAAAAhAghDwAAAABChJAHAAAAJJI2Ok/kcUCc2AwdCKB9+8ySk/1uBQAAyBNtcK6NznPaB08Bj43QkU8IeUDAjB1r1quX2YgRZj16+N0aAACQJwQ4+IiQBwQs4PXsaRaJ/PFVCHoAAACIB3PygAAGPPGCns4HAAAAYkXIAwIY8DwEPQAAAMSLkAcENOB5CHoAAACIByEPCHDA8xD0AAAAECtCHuDjNglaRTO3gOfRcTpePwcAAABkh5AH+ET74GmbhKSk2I7XcTqe/fMAAACQE0Ie4CNtjzB6dO5BT5frOLZTAAAAQG4IeUDAgx4BDwAAAPEg5AEBDnoEPAAAAMSLkOcTFs9AbkGPgAcAAIC8IOT5QMvgly/PcvjIPuiVLEnAAwAAQN6UyOPPIQH7oumr8EYe0fR86NKFVTQBAACQN/Tk+bjxNRtcIzsEPAAAAOQVIc+ngOch6AEAAABIJEKejwHPQ9ADAAAAkCiEPJ8DnoegBwAAACARCHn5vE1Cr165BzyPjtPxbK8AAAAAIK8Iefm8eMaIEYducJ0dHafjWXQDAAAAQF4R8gp4g+vssPE1AAAAgEQg5AUg6BHwAAAAACQKIc/noEfAAwAAAJBIhDwfgx4BDwAAAECiEfJ8CnolSxLwAAAAACReCb8bUBQp2HXpwiqaAAAAABKPnjyfEPAAAAAA5AdCHgAAAACECCEPAAAAAIrqnLznn3/e3nzzTatUqZLdeOON1rp16/TLfvnlF2vevLmtXLkyP9oJAEDRtWKF2fbt2V+ekmJWt25BtggAEIaQ98wzz9iAAQOse/futm3bNrvwwgtt8ODB7jw5cOCArV69Oj/bCgBA0Qx49erlftzy5QQ9AEB8Ie+FF16wUaNGWefOnd33vXr1so4dO9quXbts6NChsV4NAACIR049eHk5DgAQejGHvFWrVlnLli3Tv9f/Z8yYYW3atLF9+/bZbbfdll9tBAAAAAAkOuRVrlzZ1q5da3Xq1Ek/r2HDhi7onXfeebZ+/fpYrwoAAAAA4Pfqmq1atXKLrmRWv359mz59ur3//vuJbhsAAAAAIL9CXv/+/a1x48ZZXtagQQPXo3fffffFdeMPP/ywnX766ZaSkmLHHHOMm+P3/fffx3UdAAAAAIA8hLzXXnvNunTpku3lFSpUsDlz5lg8Zs2aZb1797b58+fbtGnT3Ny+du3a2c6dO+O6HgAAAABAnCHvxRdfdPvgffXVV1muvKn5eSVKxLXtnn3wwQfWrVs31xPYpEkTGz9+vK1Zs8YWL14c1/UAAAAAAP4QcypTuOvTp481a9bMBg0aZHfffbetW7fOevToYQsXLrTHH3/cbrjhBjsc2n9PtNl6Vvbs2eNOntTUVPdVPYA6wX9eHahHMFGfYKM+weVrbcqWNStTJrbjiuhzh9dOsFGf4KI2has+8dQpKRKJROK5sbfffttuvPFGq1q1qttWQb17o0ePttq1a9vhOHjwoF1yySW2detW+/TTT7M8RpuvDxky5JDzJ0yYYGX1xw0AAAAAQigtLc3tWa6OMU2VS2jI27Rpk11zzTVuRc1y5crZlClT7Oyzzz7cNrvN1bVCpwJejRo1Yu7Jq1mzpv3yyy+53lEUDH3CoPmVbdu2teTkZL+bg0yoT7BRn+CiNsFGfYKN+gQXtSlc9VH20bZ2sYS8uCbRvfrqq27I5qmnnmrffvutjRkzxi2UctNNN7mVMkuXLp2nO6DrVFicPXt2tgFPSpUq5U6Z6U4H7Ymp3tSANalABbEm+H/UJ9ioT3BRm2CjPsFGfYKL2hSO+sRTo5gXXunUqZNdf/31bsikevFOOukke/TRR+3jjz+29957zy2cMm/evLgarE5EBbzJkye7LRiOO+44C4OxY83Kl//jKwAAAAAUpJh78jZu3GhLliyxunXrZji/ZcuWtnTpUrePnoZt7t27N+Yb1/YJmk+neX7aK0+3IUcccYSViWWSeQAp2PXsqQD7x1fp0cPvVgEAAAAoKmIOeZ988okVK5Z1x58C2dNPP+16++IxYsQI9/Wcc87JcP64cePc1gqFOeAJQQ8AAABAYENedgEv2llnnRXXjce55kuhCngegh4AAACAghTznDzEH/AyBz3m6AEAAADIb4S8fA54HoIeAAAAgIIQ1xYKOHSbhF69cg94Hh2n47t0KdrbKwAAgEJuxQqz7duzvzwlxSzTYn0ACg4h7zAoqGntmFh68iQp6Y/jCXgAAKBQB7x69XI/bvlygh7gE4ZrHiYtpjJ69B8BLie6XMex+AoAACjUcurBy8txABKOkFcAQY+ABwAAAKCgEPLyOegR8AAAAAAUJEJePgY9Ah4AAACAgkbIy6egV7IkAQ8AAABAwWN1zXygYMc2CQAAAAD8QE9ePiHgAQAAAPADIQ8AAACx00bniTwOQMIxXBMAAACx0wbn2ug8p33wFPDYCB3wDSEPAAAA8SHAAYHGcE0AAAAACBFCHgAAAACECCEPAAAAAEKEkAcAAAAAIULIAwAAAIAQIeQBAAAAQIgQ8gAAAAAgRAh5AAAAABAihDwAAAAACBFCHgAAAACECCEPAAAAAEKEkAcAAAAAIULIAwAAAIAQIeQBAAAAQIgQ8gAAAAAgRAh5AAAAABAihDwAAAAACBFCHgAAAACECCEPAAAAAEKEkAcAAAAAIULIAwAAAIAQIeQBAAAAQIgQ8gAAAAAgRAh5AAAAABAihDwAAAAACBFCHgAAAACECCEPAAAAAEKEkAcAAAAAIULIAwAAAIAQIeQBAAAAQIgQ8gAAAAAgRAh5AAAAABAihDwAAAAACBFCHgAAAACEiK8hb/bs2dahQwerXr26JSUl2VtvveVncwAAAACg0PM15O3cudOaNGlizz33nJ/NAAAAAIDQKOHnjV9wwQXuBAAAAABIDObkAQAAAECI+NqTF689e/a4kyc1NdV93bdvnzvBf14dqEcwUZ9goz7BRW2CjfoEG/UJLmpTuOoTT52SIpFIxAJAC69MnjzZOnbsmO0xgwcPtiFDhhxy/oQJE6xs2bL53EIAAAAA8EdaWpp17tzZtm3bZhUqVAhPyMuqJ69mzZr2yy+/5HpHUTD0CcO0adOsbdu2lpyc7HdzkAn1CTbqE1zUJtioT7BRn+CiNoWrPso+lStXjinkFarhmqVKlXKnzHSneWIGCzUJNuoTbNQnuKhNsFGfYKM+wUVtCkd94qmRryFvx44d9sMPP6R/v2rVKlu6dKlVqlTJatWq5WfTAAAAAKBQ8jXkLVq0yM4999z07/v27eu+XnvttTZ+/HgfWwYAAAAAhZOvIe+cc86xgEwJBAAAAIBQYJ88AAAAAAgRQh4AAAAAhAghDwAAAABChJAHAAAAACFCyAMAAACAECHkAQAAAECIEPIAAAAAIEQIeQAAAAAQIoQ8AAAAAAgRQh4AAAAAhAghDwAAAABChJAHAAAAACFCyAMAAACAECHkAQAAAECIEPIAAAAAIEQIeQAAAAAQIoQ8AAAAAAgRQh4AAAAAhAghDwAAAABChJAHAAAAACFCyAMAAACAECHkAQAAAECIEPIAAAAAIEQIeQAAAAAQIoQ8AAAAAAgRQh4AAAAAhAghDwAAAABChJAHAAAAACFCyAMAAACAECHkAQAAAECIEPIAAAAAIEQIeQAAAAAQIoQ8AAAAAAgRQh4AAAAAhAghDwAAAABChJAHAAAAACFCyAMAAACAECHkAQAAAECIEPIAAAAAIEQIeQAAAAAQIoQ8AAAAAAgRQh4AAAAAhAghDwAAAABChJAHAAAAACFCyAMAAACAECHkAQAAAECIEPIAAAAAIEQIeQAAAAAQIoQ8AAAAAAiRQIS85557zurUqWOlS5e2M844wxYsWOB3kwAAAACgUPI95E2aNMn69u1rgwYNss8//9yaNGli7du3t82bN/vdNAAAAAAodHwPeU888YRdf/311r17d6tfv76NHDnSypYta2PHjvW7aQAAAABQ6JTw88b37t1rixcvtgEDBqSfV6xYMWvTpo3NmzfvkOP37NnjTp7U1FT3dd++fe4E/3l1oB7BRH2CjfoEF7UJNuoTbNQnuKhN4apPPHVKikQiEfPJ+vXr7dhjj7W5c+daixYt0s/v16+fzZo1yz777LMMxw8ePNiGDBlyyPVMmDDB9f4BAAAAQBilpaVZ586dbdu2bVahQoXg9uTFSz1+mr8X3ZNXs2ZNa9euXa53FAVDnzBMmzbN2rZta8nJyX43B5lQn2CjPsFFbYKN+gQb9QkualO46uONYoyFryGvcuXKVrx4cdu0aVOG8/V91apVDzm+VKlS7pSZ7jRPzGChJsFGfYKN+gQXtQk26hNs1Ce4qE3hqE88NfJ14ZWSJUta06ZNbfr06ennHTx40H0fPXwTAAAAABAb34dravjltddea82aNbPmzZvbU089ZTt37nSrbQIAAAAAClnIu/LKK23Lli02cOBA27hxo5166qn2wQcfWJUqVfxuGgAAAAAUOr6HPOnTp487AQAAAAAK+WboAAAAAIDEIeQBAAAAQIgQ8gAAAAAgRAIxJw8AAAAAfLNihdn27dlfnpJiVreuFRaEPAAAAABFO+DVq5f7ccuXF5qgx3BNAAAAAEXX9u2JPS4ACHkAAAAAECKEPAAAAAAIEUIeAAAAAIQIIQ8AAAAAQoSQBwAAAAAhQsgDAAAAgBAh5AEAAAAoulJSEntcALAZOgAAAICiq27dPzY6z2kfPAW8QrIRuhDyAAAAABRtdQtPgIsFwzUBAAAAIEQIeQAAAAAQIoQ8AAAAAAgRQh4AAAAAhAghDwAAAABChJAHAAAAACFSqLdQiEQi7mtqaqrfTcGf9u3bZ2lpaa4mycnJfjcHmVCfYKM+wUVtgo36BBv1CS5qU7jq42UeLwOFNuRt/3PDwpo1a/rdFAAAAAAokAx0xBFH5HhMUiSWKBhQBw8etPXr11tKSoolJSX53Rz82auq0L127VqrUKGC381BJtQn2KhPcFGbYKM+wUZ9govaFK76KLYp4FWvXt2KFSsW3p483bkaNWr43QxkQU9EflkEF/UJNuoTXNQm2KhPsFGf4KI2hac+ufXgeVh4BQAAAABChJAHAAAAACFCyENClSpVygYNGuS+InioT7BRn+CiNsFGfYKN+gQXtQlvfQr1wisAAAAAgIzoyQMAAACAECHkAQAAAECIEPIAAAAAIEQIeUiIhx9+2E4//XS3Mf0xxxxjHTt2tO+//97vZuFPI0aMsMaNG6fvs9KiRQt7//33/W4WsjBs2DBLSkqy2267ze+mwMwGDx7s6hF9Ovnkk/1uFqL8/PPPds0119hRRx1lZcqUsUaNGtmiRYv8blaRV6dOnUNeOzr17t3b76bBzA4cOGD33XefHXfcce51c8IJJ9j999/vNtuG/7Thud4H1K5d29WnZcuWtnDhwriuo1Bvho7gmDVrlvvFraC3f/9+++c//2nt2rWzb775xsqVK+d384q8GjVquPBQt25d9wv8xRdftEsvvdSWLFliDRo08Lt5+JN+gb/wwgsukCM49Br56KOP0r8vUYI/nUHx+++/25lnnmnnnnuu++Dq6KOPthUrVtiRRx7pd9OKPP0+U5DwfPXVV9a2bVu7/PLLfW0X/vDII4+4D4D1fkC/4/TBSPfu3d1G27fccovfzSvyevbs6V4z//73v6169er28ssvW5s2bdz76mOPPTam62B1TeSLLVu2uB49hb+zzjrL7+YgC5UqVbLHHnvMrrvuOr+bAjPbsWOH/eUvf7Hnn3/eHnjgATv11FPtqaee8rtZRZ568t566y1bunSp301BFvr3729z5syxTz75xO+mIBfqlZgyZYoL4erRg78uvvhiq1Klio0ZMyb9vE6dOrleIwUK+GfXrl1uZNzbb79tF110Ufr5TZs2tQsuuMC9R4gFwzWRL7Zt25YeJBAs+mR14sSJtnPnTjdsE8GgnnD9MtcndQgWvSnVJ6nHH3+8XX311bZmzRq/m4Q/vfPOO9asWTPXO6QPFk877TQbNWqU381CJnv37nXBoUePHgS8gNDwv+nTp9vy5cvd91988YV9+umnLkTAXxoRp/dqpUuXznC+ArhqFCvGnCDhDh486D6x0xCahg0b+t0c/GnZsmUu1O3evdvKly9vkydPtvr16/vdLJi50P3555/HPd4e+e+MM86w8ePH20knnWQbNmywIUOG2N/+9jc3jEaftMJfK1eudEPO+vbt66YJ6DWkoWYlS5a0a6+91u/m4U/qDd+6dat169bN76Ygqhc8NTXVzTEuXry4CxUPPvig+yAL/tLfFr1f0xzJU045xfW4vvrqqzZv3jw78cQTY74eQh7ypUdCb4Di+bQB+U9vUjXkTL2sr7/+unsDpOG0BD1/rV271m699VabNm3aIZ/awX/Rn2prrqRCnybC/+c//2Goc0A+VFRP3kMPPeS+V0+e/v6MHDmSkBcgGhKo15J6xBEM+h32yiuv2IQJE9ycPL0/0Af0qhGvHf9pLp56vjX/TiFc0zn+/ve/2+LFi2O+DkIeEqpPnz5uzP3s2bPdYh8IDn2y7X0CpHHd+sT76aefdgt9wD/6hb1582b3C9yjT1T1Gho+fLjt2bPH/YJHMFSsWNHq1atnP/zwg99NgZlVq1btkA+q9Mn3G2+84VubkNHq1avdwkVvvvmm301BlLvuusv15l111VXue61Kq1pptXRCnv+02qk+iNfUGvW46nfdlVde6aYNxIo5eUgIrd+jgKchgDNmzHBL8iL4n4ArQMBfrVu3dkNp9Smqd1LPhIbM6P8EvOAtkPPjjz+6P7jwn6YFZN6uR3OM1NuKYBg3bpybLxm9gAT8l5aWZsWKZYwB+nuj9wYIDq1Qr783Wkl46tSpbmX0WNGTh4QN0VSXv1YC0ljijRs3uvO1FK8misJfAwYMcENlatWq5fZeUa1mzpzpfmHAX3q9ZJ67ql/q2vOLOa3+u/POO61Dhw4uNKxfv94GDRrk3ghp2Az8d/vtt7sFJDRc84orrrAFCxbYv/71L3eC/xQYFPLUM8TWI8Gi32uag6f3BRquqS2VnnjiCTdEEP7T+zN1oGiqjUaOqOdV8ye1zUWseMUhITTxXc4555wM5+uXOxOt/afhgF27dnULRyh4a26RfoFozyIA2Vu3bp0LdL/++qvbg61Vq1Y2f/5893/4T3uzagSJPsgaOnSoG0WirUdYPCIYNExTq9ESHILn2WefdZuh33TTTe49gubi3XjjjTZw4EC/mwb7Y5V6/V7T3yCtVK/tLRTKk5OTY74O9skDAAAAgBBhTh4AAAAAhAghDwAAAABChJAHAAAAACFCyAMAAACAECHkAQAAAECIEPIAAAAAIEQIeQAAAAAQIoQ8AAAAAAgRQh4AAAAAhAghDwCATA4cOGAtW7a0yy67LMP527Zts5o1a9o999zjvr/lllusadOmVqpUKTv11FN9ai0AABkR8gAAyKR48eI2fvx4++CDD+yVV15JP//mm2+2SpUq2aBBg9LP69Gjh1155ZU+tRQAgEOVyOI8AACKvHr16tmwYcNcsDvvvPNswYIFNnHiRFu4cKGVLFnSHfPMM8+4r1u2bLEvv/zS5xYDAPAHQh4AANlQwJs8ebJ16dLFli1bZgMHDrQmTZr43SwAAHJEyAMAIBtJSUk2YsQIO+WUU6xRo0bWv39/v5sEAECumJMHAEAOxo4da2XLlrVVq1bZunXr/G4OAAC5IuQBAJCNuXPn2pNPPmlTpkyx5s2b23XXXWeRSMTvZgEAkCNCHgAAWUhLS7Nu3bpZr1697Nxzz7UxY8a4xVdGjhzpd9MAAMgRIQ8AgCwMGDDA9dpphU2pU6eOPf7449avXz/76aef3Hk//PCDLV261DZu3Gi7du1y/9dp7969PrceAFCUJUUYdwIAQAazZs2y1q1b28yZM61Vq1YZLmvfvr3t37/fPvroI9fDp2Mz0/w9hUIAAPxAyAMAAACAEGG4JgAAAACECCEPAAAAAEKEkAcAAAAAIULIAwAAAIAQIeQBAAAAQIgQ8gAAAAAgRAh5AAAAABAihDwAAAAACBFCHgAAAACECCEPAAAAAEKEkAcAAAAAIULIAwAAAAALj/8D8RE9y0LdRh0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class0 = [row for row in dataset if row[2] == 0]\n",
    "class1 = [row for row in dataset if row[2] == 1]\n",
    "\n",
    "x0 = [row[0] for row in class0]\n",
    "y0 = [row[1] for row in class0]\n",
    "\n",
    "x1 = [row[0] for row in class1]\n",
    "y1 = [row[1] for row in class1]\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.scatter(x0, y0, color='blue', marker='D', label='Class 0')\n",
    "plt.scatter(x1, y1, color='red', marker='s', label='Class 1')\n",
    "\n",
    "plt.title('Plot of the Small Contrived Dataset')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3511bd",
   "metadata": {},
   "source": [
    "Below is the complete example. We will use 2 neurons in the hidden layer. It is a binary classification problem (2 classes) so there will be two neurons in the output layer. The network will be trained for 20 epochs with a learning rate of 0.5, which is high because we are training for so few iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bbf79a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Argument lhs must have NDArray type, but got [{'weights': \n[0.82589036 0.83770555 0.894476  ]\n<NDArray 3 @cpu(0)>}, {'weights': \n[0.03315495 0.5011699  0.78476477]\n<NDArray 3 @cpu(0)>}]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m n_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m dataset))\n\u001b[0;32m      4\u001b[0m network \u001b[38;5;241m=\u001b[39m sml\u001b[38;5;241m.\u001b[39minitialize_network(n_inputs, \u001b[38;5;241m2\u001b[39m, n_outputs)\n\u001b[1;32m----> 6\u001b[0m network, train_losses, _ \u001b[38;5;241m=\u001b[39m \u001b[43msml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# <-- así, sin mx.nd.array()\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_outputs\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(network):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[49], line 9\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(network, train_data, learning_rate, n_epochs, n_outputs, test_data)\u001b[0m\n\u001b[0;32m      6\u001b[0m sum_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[1;32m----> 9\u001b[0m     activations \u001b[38;5;241m=\u001b[39m \u001b[43msml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_propagate_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m activations[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     12\u001b[0m     expected \u001b[38;5;241m=\u001b[39m mx\u001b[38;5;241m.\u001b[39mnd\u001b[38;5;241m.\u001b[39mzeros(n_outputs)\n",
      "Cell \u001b[1;32mIn[31], line 7\u001b[0m, in \u001b[0;36mforward_propagate_tensor\u001b[1;34m(network_weights, row)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m weights \u001b[38;5;129;01min\u001b[39;00m network_weights:\n\u001b[0;32m      5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m mx\u001b[38;5;241m.\u001b[39mnd\u001b[38;5;241m.\u001b[39mconcat(inputs, mx\u001b[38;5;241m.\u001b[39mnd\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m,)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     activations \u001b[38;5;241m=\u001b[39m \u001b[43mmx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m SML\u001b[38;5;241m.\u001b[39mtransfer(activations)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[1;32m<string>:76\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(lhs, rhs, transpose_a, transpose_b, forward_stype, out, name, **kwargs)\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Argument lhs must have NDArray type, but got [{'weights': \n[0.82589036 0.83770555 0.894476  ]\n<NDArray 3 @cpu(0)>}, {'weights': \n[0.03315495 0.5011699  0.78476477]\n<NDArray 3 @cpu(0)>}]"
     ]
    }
   ],
   "source": [
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set(row[-1] for row in dataset))\n",
    "\n",
    "network = sml.initialize_network(n_inputs, 2, n_outputs)\n",
    "\n",
    "network, train_losses, _ = sml.train_network(\n",
    "    network,\n",
    "    train_data=dataset,  # <-- así, sin mx.nd.array()\n",
    "    learning_rate=0.5,\n",
    "    n_epochs=20,\n",
    "    n_outputs=n_outputs\n",
    ")\n",
    "\n",
    "for i, layer in enumerate(network):\n",
    "    print(f\"Layer {i}:\")\n",
    "    for neuron in layer:\n",
    "        print({k: v if not isinstance(v, mx.nd.NDArray) else v.asnumpy().tolist()\n",
    "               for k, v in neuron.items()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxnet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
