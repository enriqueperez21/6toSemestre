{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00f5d3a7",
      "metadata": {
        "id": "00f5d3a7"
      },
      "source": [
        "# Chapter 3 Algorithm Evaluation Methods\n",
        "\n",
        "The goal of predictive modeling is to create models that make good predictions on new data.\n",
        "We don’t have access to this new data at the time of training, so we must use statistical methods\n",
        "to estimate the performance of a model on new data. This class of methods is called resampling\n",
        "methods, as they are resampling your available training data. In this tutorial, you will discover\n",
        "how to implement resampling methods from scratch in Perl. After completing this tutorial,\n",
        "you will know:\n",
        "\n",
        "* How to implement a train and test split of your data.\n",
        "* How to implement a k-fold cross-validation split of your data.\n",
        "\n",
        "Let’s get started.\n",
        "\n",
        "## 3.1 Description\n",
        "\n",
        "The goal of resampling methods is to make the best use of your training data in order to\n",
        "accurately estimate the performance of a model on new unseen data. Accurate estimates of\n",
        "performance can then be used to help you choose which set of model parameters to use or which\n",
        "model to select.\n",
        "Once you have chosen a model, you can train for final model on the entire training dataset\n",
        "and start using it to make predictions. There are two common resampling methods that you\n",
        "can use:\n",
        "\n",
        "* A train and test split of your data.\n",
        "* k-fold cross-validation.\n",
        "\n",
        "In this tutorial, we will look at using each and when to use one method over the other.\n",
        "\n",
        "## 3.2 Tutorial\n",
        "\n",
        "This tutorial is divided into 3 parts:\n",
        "\n",
        "1. Train and Test Split.\n",
        "2. k-fold Cross-Validation Split.\n",
        "3. How to Choose a Resampling Method.\n",
        "\n",
        "These steps will provide the foundations you need to handle resampling your dataset to\n",
        "estimate algorithm performance on new data.\n",
        "\n",
        "### 3.2.1 Train and Test Split\n",
        "\n",
        "The train and test split is the easiest resampling method. As such, it is the most widely used.\n",
        "The train and test split involves separating a dataset into two parts:\n",
        "\n",
        "1. Training Dataset.\n",
        "2. Test Dataset.\n",
        "\n",
        "The training dataset is used by the machine learning algorithm to train the model. The test\n",
        "dataset is held back and is used to evaluate the performance of the model. The rows assigned\n",
        "to each dataset are randomly selected. This is an attempt to ensure that the training and\n",
        "evaluation of a model is objective.\n",
        "If multiple algorithms are compared or multiple configurations of the same algorithm are\n",
        "compared, the same train and test split of the dataset should be used. This is to ensure that\n",
        "the comparison of performance is consistent or apples-to-apples. We can achieve this by seeding\n",
        "the random number generator the same way before splitting the data, or by holding the same\n",
        "split of the dataset for use by multiple algorithms. We can implement the train and test split of\n",
        "a dataset in a single function.\n",
        "Below is a function named train_test_split() to split a dataset into a train and test split.\n",
        "It accepts two arguments: the dataset to split as a list of lists and an optional split percentage.\n",
        "A default split percentage of 0.6 or 60% is used. This will assign 60% of the dataset to the\n",
        "training dataset and leave the remaining 40% to the test dataset. A 60/40 for train/test is a\n",
        "good default split of the data.\n",
        "The function first calculates how many rows the training set requires from the provided\n",
        "dataset. A copy of the original dataset is made. Random rows are selected and removed from\n",
        "the copied dataset and added to the train dataset until the train dataset contains the target\n",
        "number of rows. The rows that remain in the copy of the dataset are then returned as the\n",
        "test dataset. The int(rand()) function from the random model is used to generate a random\n",
        "integer in the range between 0 and the size of the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dcb7425",
      "metadata": {
        "id": "5dcb7425"
      },
      "outputs": [],
      "source": [
        "use strict;\n",
        "use warnings;\n",
        "use Data::Dump qw(dump);\n",
        "use List::Util qw(shuffle);\n",
        "use sml;\n",
        "use AI::MXNet qw(mx);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "182ce881",
      "metadata": {
        "id": "182ce881",
        "outputId": "5183ddfa-f7ab-4ab3-fa40-d9ec3266fbba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "*sml::train_test_split"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "Warning",
          "evalue": "Subroutine train_test_split redefined at reply input line 4.\n\nSubroutine sml::train_test_split redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/sml.pm line 22.\n",
          "output_type": "error",
          "traceback": [
            "Subroutine train_test_split redefined at reply input line 4.\n\nSubroutine sml::train_test_split redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/sml.pm line 22.\n"
          ]
        }
      ],
      "source": [
        "# Defined in Section 3.2.1 Train and Test Split\n",
        "# Function To Split a Dataset.\n",
        "# Split a dataset into a train and test set\n",
        "sub train_test_split{\n",
        "    my ($self, $dataset, %args) = (splice (@_, 0, 2), split=>0.6, @_);\n",
        "\n",
        "    if(ref($dataset) eq 'AI::MXNet::NDArray'){\n",
        "        my $train_size = $args{split} * $dataset->len;\n",
        "        my $idx = mx->nd->arange(stop=>$dataset->len) ->shuffle;\n",
        "        my $train_idx = $idx->slice(begin =>0, end => $train_size);\n",
        "        my $test_idx = $idx->slice(begin=>$train_size, end=>$dataset->len);\n",
        "        my $train = mx->nd->take($dataset,$train_idx, axis=>0);\n",
        "        my $test = mx->nd->take($dataset,$test_idx, axis=>0);\n",
        "        return $train, $test;\n",
        "\n",
        "    }elsif(ref($dataset) eq 'ARRAY'){\n",
        "        my $train_size = int($args{split} * @$dataset);\n",
        "        my @idx        = shuffle (0.. $#$dataset);\n",
        "        my @train_idx  = @idx[0.. $train_size -1];\n",
        "        my @test_idx   = @idx[$train_size .. $#$dataset];\n",
        "        my @train      = @$dataset[@train_idx]; # usa take\n",
        "        my @test       = @$dataset[@test_idx];\n",
        "        return \\@train, \\@test;\n",
        "    }\n",
        "}\n",
        "sml->add_to_class('train_test_split', \\&{'train_test_split'});\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c2bcd29",
      "metadata": {
        "id": "5c2bcd29"
      },
      "source": [
        "We can test this function using a contrived dataset of 10 rows, each with a single column.\n",
        "The complete example is listed below.\n",
        "\n",
        "The example fixes the random seed before splitting the training dataset. This is to ensure\n",
        "the exact same split of the data is made every time the code is executed. This is handy if we\n",
        "want to use the same split many times to evaluate and compare the performance of different\n",
        "algorithms. Running the example produces the output below. The data in the train and test\n",
        "set is printed, showing that 6/10 or 60% of the records were assigned to the training dataset\n",
        "and 4/10 or 40% of the records were assigned to the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b90f898",
      "metadata": {
        "id": "4b90f898",
        "outputId": "73481af9-aeb8-4034-be4e-1ca84aedc806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6], [2], [8], [9], [10], [4]]\n",
            "[[3], [7], [5], [1]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of Splitting a Contrived Dataset into Train and Test\n",
        "\n",
        "# test train/test split\n",
        "\n",
        "srand(1);\n",
        "my $dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]];\n",
        "my ($train, $test) = sml->train_test_split($dataset);\n",
        "printf \"%s\\n\", dump ($train);\n",
        "printf \"%s\\n\", dump ($test);\n",
        "\n",
        "# Example Output from Splitting a Dataset.\n",
        "# [[6], [2], [8], [9], [10], [4]]\n",
        "# [[3], [7], [5], [1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc0945fd",
      "metadata": {
        "id": "cc0945fd"
      },
      "source": [
        "### 3.2.2 k-fold Cross-Validation Split\n",
        "\n",
        "A limitation of using the train and test split method is that you get a noisy estimate of\n",
        "algorithm performance. The k-fold cross-validation method (also called just cross-validation) is\n",
        "a resampling method that provides a more accurate estimate of algorithm performance.\n",
        "It does this by first splitting the data into k groups. The algorithm is then trained and\n",
        "evaluated k times and the performance summarized by taking the mean performance score.\n",
        "Each group of data is called a fold, hence the name k-fold cross-validation. It works by first\n",
        "training the algorithm on the k-1 groups of the data and evaluating it on the kth hold-out group\n",
        "as the test set. This is repeated so that each of the k groups is given an opportunity to be held\n",
        "out and used as the test set. As such, the value of k should be divisible by the number of rows\n",
        "in your training dataset, to ensure each of the k groups has the same number of rows.\n",
        "You should choose a value for k that splits the data into groups with enough rows that each\n",
        "group is still representative of the original dataset. A good default to use is k=3 for a small\n",
        "dataset or k=10 for a larger dataset. A quick way to check if the fold sizes are representative is\n",
        "to calculate summary statistics such as mean and standard deviation and see how much the\n",
        "values differ from the same statistics on the whole dataset. We can reuse what we learned in the\n",
        "previous section in creating a train and test split here in implementing k-fold cross-validation.\n",
        "Instead of two groups, we must return k-folds or k groups of data. Below is a function named\n",
        "cross validation split() that implements the cross-validation split of data. As before, we\n",
        "create a copy of the dataset from which to draw randomly chosen rows. We calculate the size of\n",
        "each fold as the size of the dataset divided by the number of folds required.\n",
        "\n",
        "<center>fold size = count(rows) / count(folds)</center> (3.1)\n",
        "\n",
        "\n",
        "If the dataset does not cleanly divide by the number of folds, there may be some remainder\n",
        "rows and they will not be used in the split. We then create a list of rows with the required size\n",
        "and add them to a list of folds which is then returned at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e8fb615",
      "metadata": {
        "id": "3e8fb615",
        "outputId": "bbde7e6f-453c-4a4a-f8a9-a555f2d128f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "*sml::cross_validation_split"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "Warning",
          "evalue": "Subroutine cross_validation_split redefined at reply input line 4.\n\nSubroutine sml::cross_validation_split redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/sml.pm line 22.\n",
          "output_type": "error",
          "traceback": [
            "Subroutine cross_validation_split redefined at reply input line 4.\n\nSubroutine sml::cross_validation_split redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/sml.pm line 22.\n"
          ]
        }
      ],
      "source": [
        "# Defined in Section 3.2.2 k-fold Cross-Validation Split\n",
        "# Function Create A Cross-Validation Split.\n",
        "# Split a dataset into $ k $ folds\n",
        "sub cross_validation_split{\n",
        "    my ($self, $dataset, %args) = (splice (@_, 0, 2), n_folds=>10, @_);\n",
        "\n",
        "    my @dataset_split;\n",
        "\n",
        "    if(ref($dataset) eq 'AI::MXNet::NDArray'){\n",
        "        $dataset = mx->nd->array($dataset);\n",
        "        my $fold_size = int ($dataset->len / $args{n_folds});\n",
        "        my $idx = mx->nd->arange(stop=>$dataset->len)->shuffle;\n",
        "        for my $i (0 .. $args{n_folds} -1){\n",
        "            my $start = $i * $fold_size;\n",
        "            my $end = ($i == $args{n_folds} - 1) ? $dataset->len : ($i + 1) * $fold_size;\n",
        "            my @fold_idx = mx->nd->slice_axis($idx, axis => 0, begin => $start, end => $end);\n",
        "            push @dataset_split, (mx->nd->take($dataset, @fold_idx, axis=>0))->asarray; #solo cambia a un take [@$dataset[@fold_idx]]\n",
        "        }\n",
        "    }elsif(ref($dataset) eq 'ARRAY'){\n",
        "        my $fold_size = int (@$dataset / $args{n_folds});\n",
        "        my @idx = shuffle (0.. $#$dataset);\n",
        "        for my $i (0 .. $args{n_folds} -1){ #no cambia\n",
        "            my @fold_idx = @idx[$i * $fold_size.. ($i +1) * $fold_size -1]; #si cambia\n",
        "            push @dataset_split, [@$dataset[@fold_idx]]; #solo cambia a un take [@$dataset[@fold_idx]]\n",
        "        }\n",
        "    }\n",
        "    return \\@dataset_split;\n",
        "\n",
        "}\n",
        "sml->add_to_class('cross_validation_split', \\&{'cross_validation_split'});\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa0a9a0d",
      "metadata": {
        "id": "fa0a9a0d"
      },
      "source": [
        "We can test this resampling method on the same small contrived dataset as above. Each\n",
        "row has only a single column value, but we can imagine how this might scale to a standard\n",
        "machine learning dataset. The complete example is listed below. As before, we fix the seed for\n",
        "the random number generator to ensure that each time the code is executed that the same rows\n",
        "are used in the same folds. A k value of 4 is used for demonstration purposes. We would expect\n",
        "that the 10 rows divided into 4 folds will result in 2 rows per fold, with a remainder of 2 that\n",
        "will not be used in the split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52dba79a",
      "metadata": {
        "id": "52dba79a",
        "outputId": "71dcc12b-a888-405d-8214-5fd2aa6e2b58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[6], [2]], [[8], [9]], [[10], [4]], [[3], [7]], [[5], [1]]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of a Cross-Validation Split of a Contrived Dataset.\n",
        "# test cross validation split\n",
        "srand(1);\n",
        "my $dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]];\n",
        "my $folds = sml->cross_validation_split($dataset, n_folds=>5);\n",
        "printf \"%s\\n\", dump ($folds);\n",
        "\n",
        "# Example Output from Creating a Cross-Validation Split.\n",
        "# [[[6], [2]], [[8], [9]], [[10], [4]], [[3], [7]], [[5], [1]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49cdc336",
      "metadata": {
        "scrolled": true,
        "id": "49cdc336",
        "outputId": "9f155622-b340-4289-9920-27e65b9f8ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rows: 150\n",
            "cols: 5\n",
            "(\n",
            "  [5.1, 3.5, 1.4, 0.2, \"Iris-setosa\"],\n",
            "  [4.9, \"3.0\", 1.4, 0.2, \"Iris-setosa\"],\n",
            "  [4.7, 3.2, 1.3, 0.2, \"Iris-setosa\"],\n",
            "  [4.6, 3.1, 1.5, 0.2, \"Iris-setosa\"],\n",
            "  [\"5.0\", 3.6, 1.4, 0.2, \"Iris-setosa\"],\n",
            ")"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my ($dataset, $header) = sml->load_csv('./data/iris.csv');\n",
        "printf \"rows: %d\\n\", scalar @$dataset;\n",
        "printf \"cols: %d\\n\", scalar @{$dataset->[0]};\n",
        "print dump @$dataset[0 .. 4];\n",
        "\n",
        "# rows: 150\n",
        "# cols: 5\n",
        "# (\n",
        "#   [5.1, 3.5, 1.4, 0.2, \"Iris-setosa\"],\n",
        "#   [4.9, \"3.0\", 1.4, 0.2, \"Iris-setosa\"],\n",
        "#   [4.7, 3.2, 1.3, 0.2, \"Iris-setosa\"],\n",
        "#   [4.6, 3.1, 1.5, 0.2, \"Iris-setosa\"],\n",
        "#   [\"5.0\", 3.6, 1.4, 0.2, \"Iris-setosa\"],\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c59e6d",
      "metadata": {
        "id": "54c59e6d",
        "outputId": "36c73c2c-d62b-4292-97fb-6ce50c7e24bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lookup:\n",
            "{ \"Iris-setosa\" => 0, \"Iris-versicolor\" => 1, \"Iris-virginica\" => 2 }\n",
            "rev_lookup:\n",
            "{ \"0\" => \"Iris-setosa\", \"1\" => \"Iris-versicolor\", \"2\" => \"Iris-virginica\" }\n",
            "Modified dataset:\n",
            "(\n",
            "  [5.1, 3.5, 1.4, 0.2, 0],\n",
            "  [4.9, \"3.0\", 1.4, 0.2, 0],\n",
            "  [4.7, 3.2, 1.3, 0.2, 0],\n",
            "  [4.6, 3.1, 1.5, 0.2, 0],\n",
            "  [\"5.0\", 3.6, 1.4, 0.2, 0],\n",
            ")"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my $lookup = sml->str_column_to_int ($dataset, -1);\n",
        "my $rev_lookup = {reverse %$lookup};\n",
        "printf \"lookup:\\n%s\\n\", dump $lookup;\n",
        "printf \"rev_lookup:\\n%s\\n\", dump $rev_lookup;\n",
        "printf \"Modified dataset:\\n%s\", dump @$dataset[0 .. 4];\n",
        "\n",
        "# lookup:\n",
        "# { \"Iris-setosa\" => 0, \"Iris-versicolor\" => 1, \"Iris-virginica\" => 2 }\n",
        "# rev_lookup:\n",
        "# { \"0\" => \"Iris-setosa\", \"1\" => \"Iris-versicolor\", \"2\" => \"Iris-virginica\" }\n",
        "# Modified dataset:\n",
        "# (\n",
        "#   [5.1, 3.5, 1.4, 0.2, 0],\n",
        "#   [4.9, \"3.0\", 1.4, 0.2, 0],\n",
        "#   [4.7, 3.2, 1.3, 0.2, 0],\n",
        "#   [4.6, 3.1, 1.5, 0.2, 0],\n",
        "#   [\"5.0\", 3.6, 1.4, 0.2, 0],\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "055669a2",
      "metadata": {
        "id": "055669a2",
        "outputId": "f2283ea0-a5b4-4d01-80e1-320dc74c2eca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "*sml::count_labels"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "Warning",
          "evalue": "Subroutine count_labels redefined at reply input line 1.\n\nSubroutine sml::count_labels redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/sml.pm line 22.\n",
          "output_type": "error",
          "traceback": [
            "Subroutine count_labels redefined at reply input line 1.\n\nSubroutine sml::count_labels redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/sml.pm line 22.\n"
          ]
        }
      ],
      "source": [
        "sub count_labels{\n",
        "my ($self, $dataset) = @_;\n",
        "my %counts = ();\n",
        "map {$counts{\"$_->[-1]\"}++} @$dataset;\n",
        "return \\%counts;\n",
        "}\n",
        "sml->add_to_class('count_labels', \\&{'count_labels'});\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94237945",
      "metadata": {
        "id": "94237945",
        "outputId": "6d2a61f2-e778-4b1c-c138-876663fa849b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ \"0\" => 50, \"1\" => 50, \"2\" => 50 }"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my $counts = sml->count_labels ($dataset);\n",
        "print dump $counts;\n",
        "\n",
        "# { \"Iris-setosa\" => 50, \"Iris-versicolor\" => 50, \"Iris-virginica\" => 50 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "669cbdb0",
      "metadata": {
        "id": "669cbdb0",
        "outputId": "da1356a8-6ae8-406f-aaa3-c2ce95a3a917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iris-setosa => 50 Iris-virginica => 50 Iris-versicolor => 50 "
          ]
        }
      ],
      "source": [
        "for my $key (keys %$counts){\n",
        "    printf \"%s => %d \", $rev_lookup->{$key}, $counts->{$key};\n",
        "}\n",
        "\n",
        "# Iris-virginica => 50 Iris-versicolor => 50 Iris-setosa => 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de964fdd",
      "metadata": {
        "id": "de964fdd",
        "outputId": "76de02c8-b3b4-42e1-b00d-3ea47ff49c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train size: 120, test size: 30"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "srand(1);\n",
        "my ($train, $test) = sml->train_test_split($dataset, split=>0.8);\n",
        "printf \"train size: %d, test size: %d\", scalar (@$train), scalar (@$test);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ab785d",
      "metadata": {
        "id": "c7ab785d",
        "outputId": "2ca32687-b4b2-4057-a8ed-6bf83246c18a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ \"0\" => 40, \"1\" => 42, \"2\" => 38 }"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print dump (sml->count_labels($train));\n",
        "# { \"0\" => 40, \"1\" => 42, \"2\" => 38 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04e42344",
      "metadata": {
        "id": "04e42344",
        "outputId": "9118cf9f-4e2b-47ce-894a-58f7e7184d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ \"0\" => 10, \"1\" => 8, \"2\" => 12 }"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print dump (sml->count_labels($test));\n",
        "# { \"0\" => 10, \"1\" => 8, \"2\" => 12 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cdeee90",
      "metadata": {
        "id": "4cdeee90",
        "outputId": "d707f116-1e75-4e8b-9378-db3c0db3847a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(\n",
            "  [7.2, 3.2, \"6.0\", 1.8, 2],\n",
            "  [5.9, \"3.0\", 4.2, 1.5, 1],\n",
            "  [6.5, \"3.0\", 5.5, 1.8, 2],\n",
            "  [5.5, 2.4, 3.7, \"1.0\", 1],\n",
            "  [5.8, 2.6, \"4.0\", 1.2, 1],\n",
            "  [4.8, 3.4, 1.6, 0.2, 0],\n",
            "  [4.8, 3.4, 1.9, 0.2, 0],\n",
            "  [6.1, 2.9, 4.7, 1.4, 1],\n",
            "  [6.4, 3.2, 5.3, 2.3, 2],\n",
            "  [\"5.0\", 3.2, 1.2, 0.2, 0],\n",
            ")"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print dump @$train[0 .. 9];\n",
        "# (\n",
        "#   [7.2, 3.2, \"6.0\", 1.8, 2],\n",
        "#   [5.9, \"3.0\", 4.2, 1.5, 1],\n",
        "#   [6.5, \"3.0\", 5.5, 1.8, 2],\n",
        "#   [5.5, 2.4, 3.7, \"1.0\", 1],\n",
        "#   [5.8, 2.6, \"4.0\", 1.2, 1],\n",
        "#   [4.8, 3.4, 1.6, 0.2, 0],\n",
        "#   [4.8, 3.4, 1.9, 0.2, 0],\n",
        "#   [6.1, 2.9, 4.7, 1.4, 1],\n",
        "#   [6.4, 3.2, 5.3, 2.3, 2],\n",
        "#   [\"5.0\", 3.2, 1.2, 0.2, 0],\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "937af420",
      "metadata": {
        "id": "937af420",
        "outputId": "877e862d-9929-4dce-bea3-922a15d9eae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(\n",
            "  [6.7, 2.5, 5.8, 1.8, 2],\n",
            "  [4.6, 3.2, 1.4, 0.2, 0],\n",
            "  [6.1, 2.8, 4.7, 1.2, 1],\n",
            "  [6.5, 3.2, 5.1, \"2.0\", 2],\n",
            "  [4.4, 3.2, 1.3, 0.2, 0],\n",
            "  [7.7, 3.8, 6.7, 2.2, 2],\n",
            "  [6.3, 2.5, 4.9, 1.5, 1],\n",
            "  [6.7, 3.3, 5.7, 2.5, 2],\n",
            "  [6.8, 3.2, 5.9, 2.3, 2],\n",
            "  [5.5, 2.4, 3.8, 1.1, 1],\n",
            ")"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print dump @$test[0 .. 9];\n",
        "# (\n",
        "#   [6.7, 2.5, 5.8, 1.8, 2],\n",
        "#   [4.6, 3.2, 1.4, 0.2, 0],\n",
        "#   [6.1, 2.8, 4.7, 1.2, 1],\n",
        "#   [6.5, 3.2, 5.1, \"2.0\", 2],\n",
        "#   [4.4, 3.2, 1.3, 0.2, 0],\n",
        "#   [7.7, 3.8, 6.7, 2.2, 2],\n",
        "#   [6.3, 2.5, 4.9, 1.5, 1],\n",
        "#   [6.7, 3.3, 5.7, 2.5, 2],\n",
        "#   [6.8, 3.2, 5.9, 2.3, 2],\n",
        "#   [5.5, 2.4, 3.8, 1.1, 1],\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5360cf33",
      "metadata": {
        "id": "5360cf33",
        "outputId": "6da37180-99b8-4249-b144-949d24010c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(\n",
            "  [\n",
            "    [7.2, 3.2, \"6.0\", 1.8, 2],\n",
            "    [5.9, \"3.0\", 4.2, 1.5, 1],\n",
            "    [6.5, \"3.0\", 5.5, 1.8, 2],\n",
            "    [5.5, 2.4, 3.7, \"1.0\", 1],\n",
            "    [5.8, 2.6, \"4.0\", 1.2, 1],\n",
            "    [4.8, 3.4, 1.6, 0.2, 0],\n",
            "    [4.8, 3.4, 1.9, 0.2, 0],\n",
            "    [6.1, 2.9, 4.7, 1.4, 1],\n",
            "    [6.4, 3.2, 5.3, 2.3, 2],\n",
            "    [\"5.0\", 3.2, 1.2, 0.2, 0],\n",
            "    [7.1, \"3.0\", 5.9, 2.1, 2],\n",
            "    [6.9, 3.1, 4.9, 1.5, 1],\n",
            "    [6.1, \"3.0\", 4.9, 1.8, 2],\n",
            "    [5.2, 2.7, 3.9, 1.4, 1],\n",
            "    [6.3, 2.9, 5.6, 1.8, 2],\n",
            "  ],\n",
            "  [\n",
            "    [6.2, 2.8, 4.8, 1.8, 2],\n",
            "    [6.7, \"3.0\", 5.2, 2.3, 2],\n",
            "    [5.4, 3.7, 1.5, 0.2, 0],\n",
            "    [5.7, \"3.0\", 4.2, 1.2, 1],\n",
            "    [6.5, \"3.0\", 5.2, \"2.0\", 2],\n",
            "    [4.5, 2.3, 1.3, 0.3, 0],\n",
            "    [5.6, \"3.0\", 4.1, 1.3, 1],\n",
            "    [5.4, 3.9, 1.3, 0.4, 0],\n",
            "    [5.1, 3.7, 1.5, 0.4, 0],\n",
            "    [4.9, 3.1, 1.5, 0.1, 0],\n",
            "    [5.6, 2.9, 3.6, 1.3, 1],\n",
            "    [5.6, 2.8, 4.9, \"2.0\", 2],\n",
            "    [6.9, 3.1, 5.4, 2.1, 2],\n",
            "    [5.8, 2.8, 5.1, 2.4, 2],\n",
            "    [6.3, 3.4, 5.6, 2.4, 2],\n",
            "  ],\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "srand(1);\n",
        "my $folds = sml->cross_validation_split($dataset, n_folds=>10);\n",
        "printf \"%s\\n\", dump (@$folds[0 .. 1]);\n",
        "\n",
        "# (\n",
        "#   [\n",
        "#     [7.2, 3.2, \"6.0\", 1.8, 2],\n",
        "#     [5.9, \"3.0\", 4.2, 1.5, 1],\n",
        "#     [6.5, \"3.0\", 5.5, 1.8, 2],\n",
        "#     [5.5, 2.4, 3.7, \"1.0\", 1],\n",
        "#     [5.8, 2.6, \"4.0\", 1.2, 1],\n",
        "#     [4.8, 3.4, 1.6, 0.2, 0],\n",
        "#     [4.8, 3.4, 1.9, 0.2, 0],\n",
        "#     [6.1, 2.9, 4.7, 1.4, 1],\n",
        "#     [6.4, 3.2, 5.3, 2.3, 2],\n",
        "#     [\"5.0\", 3.2, 1.2, 0.2, 0],\n",
        "#     [7.1, \"3.0\", 5.9, 2.1, 2],\n",
        "#     [6.9, 3.1, 4.9, 1.5, 1],\n",
        "#     [6.1, \"3.0\", 4.9, 1.8, 2],\n",
        "#     [5.2, 2.7, 3.9, 1.4, 1],\n",
        "#     [6.3, 2.9, 5.6, 1.8, 2],\n",
        "#   ],\n",
        "#   ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc5f189b",
      "metadata": {
        "id": "dc5f189b",
        "outputId": "ec944dc6-4e01-4deb-875b-3982907ce7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rows per fold: 15\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "printf \"rows per fold: %d\\n\", scalar @{$folds->[0]};\n",
        "# rows per fold:15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c36cefe",
      "metadata": {
        "id": "9c36cefe",
        "outputId": "851cfb68-2bc7-4ad9-e099-fb2937eb6ed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ \"0\" => 3, \"1\" => 6, \"2\" => 6 }\n",
            "{ \"0\" => 5, \"1\" => 3, \"2\" => 7 }\n",
            "{ \"0\" => 5, \"1\" => 4, \"2\" => 6 }\n",
            "{ \"0\" => 5, \"1\" => 4, \"2\" => 6 }\n",
            "{ \"0\" => 6, \"1\" => 8, \"2\" => 1 }\n",
            "{ \"0\" => 5, \"1\" => 8, \"2\" => 2 }\n",
            "{ \"0\" => 6, \"1\" => 4, \"2\" => 5 }\n",
            "{ \"0\" => 5, \"1\" => 5, \"2\" => 5 }\n",
            "{ \"0\" => 4, \"1\" => 4, \"2\" => 7 }\n",
            "{ \"0\" => 6, \"1\" => 4, \"2\" => 5 }\n"
          ]
        }
      ],
      "source": [
        "for my $medicion (map {sml->count_labels($_)} @$folds){\n",
        " printf \"%s\\n\", dump $medicion;\n",
        "}\n",
        "\n",
        "# { \"0\" => 3, \"1\" => 6, \"2\" => 6 }\n",
        "# { \"0\" => 5, \"1\" => 3, \"2\" => 7 }\n",
        "# { \"0\" => 5, \"1\" => 4, \"2\" => 6 }\n",
        "# { \"0\" => 5, \"1\" => 4, \"2\" => 6 }\n",
        "# { \"0\" => 6, \"1\" => 8, \"2\" => 1 }\n",
        "# { \"0\" => 5, \"1\" => 8, \"2\" => 2 }\n",
        "# { \"0\" => 6, \"1\" => 4, \"2\" => 5 }\n",
        "# { \"0\" => 5, \"1\" => 5, \"2\" => 5 }\n",
        "# { \"0\" => 4, \"1\" => 4, \"2\" => 7 }\n",
        "# { \"0\" => 6, \"1\" => 4, \"2\" => 5 }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a2cc2f",
      "metadata": {
        "id": "53a2cc2f"
      },
      "source": [
        "### 3.2.3 How to Choose a Resampling Method\n",
        "\n",
        "The gold standard for estimating the performance of machine learning algorithms on new data\n",
        "is k-fold cross-validation. When well-configured, k-fold cross-validation gives a robust estimate\n",
        "of performance compared to other methods such as the train and test split. The downside of\n",
        "cross-validation is that it can be time-consuming to run, requiring k different models to be\n",
        "trained and evaluated. This is a problem if you have a very large dataset or if you are evaluating\n",
        "a model that takes a long time to train.\n",
        "The train and test split resampling method is the most widely used. This is because it is easy\n",
        "to understand and implement, and because it gives a quick estimate of algorithm performance.\n",
        "Only a single model is constructed and evaluated. Although the train and test split method can\n",
        "give a noisy or unreliable estimate of the performance of a model on new data, this becomes\n",
        "less of a problem if you have a very large dataset.\n",
        "Large datasets are those in the hundreds of thousands or millions of records, large enough\n",
        "that splitting it in half results in two datasets that have nearly equivalent statistical properties.\n",
        "In such cases, there may be little need to use k-fold cross-validation as an evaluation of the\n",
        "algorithm and a train and test split may be just as reliable.\n",
        "\n",
        "## 3.3 Extensions\n",
        "\n",
        "In this tutorial, we have looked at the two most common resampling methods. There are other\n",
        "methods you may want to investigate and implement as extensions to this tutorial. For example:\n",
        "* Repeated Train and Test. This is where the train and test split is used, but the process\n",
        "is repeated many times.\n",
        "* LOOCV or Leave One Out Cross-Validation. This is a form of k-fold cross-validation\n",
        "where the value of k is fixed at 1.\n",
        "* Stratification. In classification problems, this is where the balance of class values in each\n",
        "group is forced to match the original dataset.\n",
        "\n",
        "## 3.4 Review\n",
        "\n",
        "In this tutorial, you discovered how to implement resampling methods in Python from scratch.\n",
        "Specifically, you learned:\n",
        "* How to implement the train and test split method.\n",
        "* How to implement the k-fold cross-validation method.\n",
        "* When to use each method."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "IPerl 0.011",
      "language": "perl",
      "name": "iperl"
    },
    "language_info": {
      "file_extension": ".pl",
      "mimetype": "text/x-perl",
      "name": "perl",
      "version": "5.32.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}